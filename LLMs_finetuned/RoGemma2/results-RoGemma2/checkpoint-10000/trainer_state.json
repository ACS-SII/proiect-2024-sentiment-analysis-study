{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.7586206896551726,
  "eval_steps": 500,
  "global_step": 10000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005517241379310344,
      "grad_norm": 1.0467263460159302,
      "learning_rate": 0.00019999906029291887,
      "loss": 1.8439,
      "step": 20
    },
    {
      "epoch": 0.011034482758620689,
      "grad_norm": 0.888068675994873,
      "learning_rate": 0.0001999948838526154,
      "loss": 1.0769,
      "step": 40
    },
    {
      "epoch": 0.016551724137931035,
      "grad_norm": 0.6164122223854065,
      "learning_rate": 0.00019998736640658855,
      "loss": 0.998,
      "step": 60
    },
    {
      "epoch": 0.022068965517241378,
      "grad_norm": 0.4628562927246094,
      "learning_rate": 0.0001999765082060095,
      "loss": 1.0736,
      "step": 80
    },
    {
      "epoch": 0.027586206896551724,
      "grad_norm": 0.5862522721290588,
      "learning_rate": 0.00019996230961366994,
      "loss": 1.0184,
      "step": 100
    },
    {
      "epoch": 0.03310344827586207,
      "grad_norm": 0.5534142851829529,
      "learning_rate": 0.00019994477110396984,
      "loss": 0.9737,
      "step": 120
    },
    {
      "epoch": 0.038620689655172416,
      "grad_norm": 0.5860959887504578,
      "learning_rate": 0.00019992389326290184,
      "loss": 0.9706,
      "step": 140
    },
    {
      "epoch": 0.044137931034482755,
      "grad_norm": 0.4637620151042938,
      "learning_rate": 0.0001998996767880315,
      "loss": 0.9157,
      "step": 160
    },
    {
      "epoch": 0.0496551724137931,
      "grad_norm": 0.48466479778289795,
      "learning_rate": 0.00019987212248847403,
      "loss": 0.8935,
      "step": 180
    },
    {
      "epoch": 0.05517241379310345,
      "grad_norm": 0.5099786520004272,
      "learning_rate": 0.00019984123128486726,
      "loss": 0.9871,
      "step": 200
    },
    {
      "epoch": 0.060689655172413794,
      "grad_norm": 0.34865307807922363,
      "learning_rate": 0.00019980700420934086,
      "loss": 0.9393,
      "step": 220
    },
    {
      "epoch": 0.06620689655172414,
      "grad_norm": 0.6240893602371216,
      "learning_rate": 0.0001997694424054819,
      "loss": 0.9299,
      "step": 240
    },
    {
      "epoch": 0.07172413793103448,
      "grad_norm": 0.5131316184997559,
      "learning_rate": 0.0001997285471282966,
      "loss": 0.8576,
      "step": 260
    },
    {
      "epoch": 0.07724137931034483,
      "grad_norm": 0.4997433125972748,
      "learning_rate": 0.0001996843197441684,
      "loss": 0.9245,
      "step": 280
    },
    {
      "epoch": 0.08275862068965517,
      "grad_norm": 0.5643815994262695,
      "learning_rate": 0.00019963676173081235,
      "loss": 0.951,
      "step": 300
    },
    {
      "epoch": 0.08827586206896551,
      "grad_norm": 0.5125375986099243,
      "learning_rate": 0.0001995858746772257,
      "loss": 0.844,
      "step": 320
    },
    {
      "epoch": 0.09379310344827586,
      "grad_norm": 0.5588558912277222,
      "learning_rate": 0.0001995316602836348,
      "loss": 0.9719,
      "step": 340
    },
    {
      "epoch": 0.0993103448275862,
      "grad_norm": 0.5408992171287537,
      "learning_rate": 0.00019947412036143837,
      "loss": 0.9996,
      "step": 360
    },
    {
      "epoch": 0.10482758620689656,
      "grad_norm": 0.7600042223930359,
      "learning_rate": 0.00019941325683314675,
      "loss": 0.9782,
      "step": 380
    },
    {
      "epoch": 0.1103448275862069,
      "grad_norm": 0.6582916975021362,
      "learning_rate": 0.00019934907173231806,
      "loss": 0.9384,
      "step": 400
    },
    {
      "epoch": 0.11586206896551725,
      "grad_norm": 0.4780871272087097,
      "learning_rate": 0.00019928156720348982,
      "loss": 0.9476,
      "step": 420
    },
    {
      "epoch": 0.12137931034482759,
      "grad_norm": 0.5107610821723938,
      "learning_rate": 0.00019921074550210765,
      "loss": 0.8567,
      "step": 440
    },
    {
      "epoch": 0.12689655172413794,
      "grad_norm": 0.37418726086616516,
      "learning_rate": 0.0001991366089944497,
      "loss": 0.8225,
      "step": 460
    },
    {
      "epoch": 0.13241379310344828,
      "grad_norm": 0.3908826410770416,
      "learning_rate": 0.00019905916015754764,
      "loss": 0.8949,
      "step": 480
    },
    {
      "epoch": 0.13793103448275862,
      "grad_norm": 0.47748205065727234,
      "learning_rate": 0.00019897840157910395,
      "loss": 0.9042,
      "step": 500
    },
    {
      "epoch": 0.13793103448275862,
      "eval_loss": 0.8900888562202454,
      "eval_runtime": 57.5743,
      "eval_samples_per_second": 15.632,
      "eval_steps_per_second": 1.963,
      "step": 500
    },
    {
      "epoch": 0.14344827586206896,
      "grad_norm": 0.43436118960380554,
      "learning_rate": 0.00019889433595740542,
      "loss": 0.9862,
      "step": 520
    },
    {
      "epoch": 0.1489655172413793,
      "grad_norm": 0.4508359730243683,
      "learning_rate": 0.00019880696610123292,
      "loss": 0.999,
      "step": 540
    },
    {
      "epoch": 0.15448275862068966,
      "grad_norm": 0.46803924441337585,
      "learning_rate": 0.00019871629492976777,
      "loss": 0.9306,
      "step": 560
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.48469212651252747,
      "learning_rate": 0.00019862232547249398,
      "loss": 0.8516,
      "step": 580
    },
    {
      "epoch": 0.16551724137931034,
      "grad_norm": 0.44950807094573975,
      "learning_rate": 0.00019852506086909708,
      "loss": 0.8663,
      "step": 600
    },
    {
      "epoch": 0.17103448275862068,
      "grad_norm": 0.4730515778064728,
      "learning_rate": 0.00019842450436935934,
      "loss": 0.946,
      "step": 620
    },
    {
      "epoch": 0.17655172413793102,
      "grad_norm": 0.5775305032730103,
      "learning_rate": 0.00019832065933305106,
      "loss": 1.0204,
      "step": 640
    },
    {
      "epoch": 0.1820689655172414,
      "grad_norm": 0.5201018452644348,
      "learning_rate": 0.00019821352922981834,
      "loss": 0.8598,
      "step": 660
    },
    {
      "epoch": 0.18758620689655173,
      "grad_norm": 0.4961722493171692,
      "learning_rate": 0.00019810311763906723,
      "loss": 0.7763,
      "step": 680
    },
    {
      "epoch": 0.19310344827586207,
      "grad_norm": 0.5185037851333618,
      "learning_rate": 0.00019798942824984396,
      "loss": 0.8822,
      "step": 700
    },
    {
      "epoch": 0.1986206896551724,
      "grad_norm": 0.5615907311439514,
      "learning_rate": 0.00019787246486071197,
      "loss": 1.0759,
      "step": 720
    },
    {
      "epoch": 0.20413793103448277,
      "grad_norm": 0.4865291714668274,
      "learning_rate": 0.0001977522313796246,
      "loss": 0.9321,
      "step": 740
    },
    {
      "epoch": 0.2096551724137931,
      "grad_norm": 0.501975953578949,
      "learning_rate": 0.00019762873182379496,
      "loss": 0.9149,
      "step": 760
    },
    {
      "epoch": 0.21517241379310345,
      "grad_norm": 0.48373308777809143,
      "learning_rate": 0.00019750197031956135,
      "loss": 0.8288,
      "step": 780
    },
    {
      "epoch": 0.2206896551724138,
      "grad_norm": 0.4916895031929016,
      "learning_rate": 0.00019737195110224956,
      "loss": 0.8878,
      "step": 800
    },
    {
      "epoch": 0.22620689655172413,
      "grad_norm": 0.48891329765319824,
      "learning_rate": 0.00019723867851603136,
      "loss": 0.8965,
      "step": 820
    },
    {
      "epoch": 0.2317241379310345,
      "grad_norm": 0.6805728673934937,
      "learning_rate": 0.0001971021570137793,
      "loss": 0.9112,
      "step": 840
    },
    {
      "epoch": 0.23724137931034484,
      "grad_norm": 0.45583799481391907,
      "learning_rate": 0.00019696239115691793,
      "loss": 0.8797,
      "step": 860
    },
    {
      "epoch": 0.24275862068965517,
      "grad_norm": 0.5917681455612183,
      "learning_rate": 0.00019681938561527142,
      "loss": 0.9696,
      "step": 880
    },
    {
      "epoch": 0.2482758620689655,
      "grad_norm": 0.7771403789520264,
      "learning_rate": 0.00019667314516690762,
      "loss": 0.9096,
      "step": 900
    },
    {
      "epoch": 0.2537931034482759,
      "grad_norm": 0.36161190271377563,
      "learning_rate": 0.00019652367469797822,
      "loss": 0.8973,
      "step": 920
    },
    {
      "epoch": 0.2593103448275862,
      "grad_norm": 0.4137650728225708,
      "learning_rate": 0.00019637097920255565,
      "loss": 0.836,
      "step": 940
    },
    {
      "epoch": 0.26482758620689656,
      "grad_norm": 0.4316840171813965,
      "learning_rate": 0.00019621506378246614,
      "loss": 0.8936,
      "step": 960
    },
    {
      "epoch": 0.27034482758620687,
      "grad_norm": 0.5544753670692444,
      "learning_rate": 0.0001960559336471194,
      "loss": 0.821,
      "step": 980
    },
    {
      "epoch": 0.27586206896551724,
      "grad_norm": 0.4085812568664551,
      "learning_rate": 0.0001958935941133343,
      "loss": 0.9307,
      "step": 1000
    },
    {
      "epoch": 0.27586206896551724,
      "eval_loss": 0.8730624914169312,
      "eval_runtime": 55.605,
      "eval_samples_per_second": 16.186,
      "eval_steps_per_second": 2.032,
      "step": 1000
    },
    {
      "epoch": 0.2813793103448276,
      "grad_norm": 0.4537787437438965,
      "learning_rate": 0.0001957280506051615,
      "loss": 0.9484,
      "step": 1020
    },
    {
      "epoch": 0.2868965517241379,
      "grad_norm": 0.5575349926948547,
      "learning_rate": 0.00019555930865370203,
      "loss": 0.8017,
      "step": 1040
    },
    {
      "epoch": 0.2924137931034483,
      "grad_norm": 0.5312935709953308,
      "learning_rate": 0.00019538737389692264,
      "loss": 0.8653,
      "step": 1060
    },
    {
      "epoch": 0.2979310344827586,
      "grad_norm": 0.5010756254196167,
      "learning_rate": 0.00019521225207946725,
      "loss": 0.9178,
      "step": 1080
    },
    {
      "epoch": 0.30344827586206896,
      "grad_norm": 0.30118662118911743,
      "learning_rate": 0.00019503394905246517,
      "loss": 0.8499,
      "step": 1100
    },
    {
      "epoch": 0.30896551724137933,
      "grad_norm": 0.6727914810180664,
      "learning_rate": 0.00019485247077333554,
      "loss": 0.8947,
      "step": 1120
    },
    {
      "epoch": 0.31448275862068964,
      "grad_norm": 0.4808826148509979,
      "learning_rate": 0.00019466782330558827,
      "loss": 0.906,
      "step": 1140
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6893023252487183,
      "learning_rate": 0.00019448001281862143,
      "loss": 0.8723,
      "step": 1160
    },
    {
      "epoch": 0.3255172413793103,
      "grad_norm": 0.523507297039032,
      "learning_rate": 0.0001942890455875152,
      "loss": 0.9133,
      "step": 1180
    },
    {
      "epoch": 0.3310344827586207,
      "grad_norm": 0.4033757746219635,
      "learning_rate": 0.0001940949279928222,
      "loss": 0.8184,
      "step": 1200
    },
    {
      "epoch": 0.33655172413793105,
      "grad_norm": 0.5772790312767029,
      "learning_rate": 0.00019389766652035408,
      "loss": 0.8824,
      "step": 1220
    },
    {
      "epoch": 0.34206896551724136,
      "grad_norm": 0.5183663964271545,
      "learning_rate": 0.00019369726776096523,
      "loss": 0.8729,
      "step": 1240
    },
    {
      "epoch": 0.34758620689655173,
      "grad_norm": 0.7043545842170715,
      "learning_rate": 0.0001934937384103322,
      "loss": 0.9915,
      "step": 1260
    },
    {
      "epoch": 0.35310344827586204,
      "grad_norm": 0.5590131282806396,
      "learning_rate": 0.00019328708526873011,
      "loss": 0.9613,
      "step": 1280
    },
    {
      "epoch": 0.3586206896551724,
      "grad_norm": 0.6334705352783203,
      "learning_rate": 0.00019307731524080554,
      "loss": 0.9484,
      "step": 1300
    },
    {
      "epoch": 0.3641379310344828,
      "grad_norm": 0.5011433362960815,
      "learning_rate": 0.0001928644353353457,
      "loss": 0.8887,
      "step": 1320
    },
    {
      "epoch": 0.3696551724137931,
      "grad_norm": 0.4442373514175415,
      "learning_rate": 0.00019264845266504435,
      "loss": 0.8408,
      "step": 1340
    },
    {
      "epoch": 0.37517241379310345,
      "grad_norm": 0.4940446615219116,
      "learning_rate": 0.00019242937444626402,
      "loss": 0.8557,
      "step": 1360
    },
    {
      "epoch": 0.38068965517241377,
      "grad_norm": 0.4431842565536499,
      "learning_rate": 0.00019220720799879507,
      "loss": 0.9201,
      "step": 1380
    },
    {
      "epoch": 0.38620689655172413,
      "grad_norm": 0.33707743883132935,
      "learning_rate": 0.0001919819607456109,
      "loss": 0.8434,
      "step": 1400
    },
    {
      "epoch": 0.3917241379310345,
      "grad_norm": 0.4625033736228943,
      "learning_rate": 0.00019175364021262027,
      "loss": 0.8254,
      "step": 1420
    },
    {
      "epoch": 0.3972413793103448,
      "grad_norm": 0.5518327951431274,
      "learning_rate": 0.00019152225402841553,
      "loss": 0.795,
      "step": 1440
    },
    {
      "epoch": 0.4027586206896552,
      "grad_norm": 0.39433616399765015,
      "learning_rate": 0.00019128780992401783,
      "loss": 0.7489,
      "step": 1460
    },
    {
      "epoch": 0.40827586206896554,
      "grad_norm": 0.5803388953208923,
      "learning_rate": 0.00019105031573261888,
      "loss": 0.9133,
      "step": 1480
    },
    {
      "epoch": 0.41379310344827586,
      "grad_norm": 0.40817031264305115,
      "learning_rate": 0.0001908097793893192,
      "loss": 0.966,
      "step": 1500
    },
    {
      "epoch": 0.41379310344827586,
      "eval_loss": 0.8629173040390015,
      "eval_runtime": 55.5909,
      "eval_samples_per_second": 16.19,
      "eval_steps_per_second": 2.033,
      "step": 1500
    },
    {
      "epoch": 0.4193103448275862,
      "grad_norm": 0.6925487518310547,
      "learning_rate": 0.00019056620893086293,
      "loss": 0.9158,
      "step": 1520
    },
    {
      "epoch": 0.42482758620689653,
      "grad_norm": 0.4987557530403137,
      "learning_rate": 0.00019031961249536944,
      "loss": 0.8365,
      "step": 1540
    },
    {
      "epoch": 0.4303448275862069,
      "grad_norm": 0.4926753342151642,
      "learning_rate": 0.00019006999832206126,
      "loss": 0.8941,
      "step": 1560
    },
    {
      "epoch": 0.43586206896551727,
      "grad_norm": 0.3503285348415375,
      "learning_rate": 0.00018981737475098882,
      "loss": 0.8677,
      "step": 1580
    },
    {
      "epoch": 0.4413793103448276,
      "grad_norm": 0.3997167944908142,
      "learning_rate": 0.00018956175022275201,
      "loss": 0.7989,
      "step": 1600
    },
    {
      "epoch": 0.44689655172413795,
      "grad_norm": 0.4908469319343567,
      "learning_rate": 0.0001893031332782179,
      "loss": 0.7761,
      "step": 1620
    },
    {
      "epoch": 0.45241379310344826,
      "grad_norm": 0.4412219226360321,
      "learning_rate": 0.0001890415325582355,
      "loss": 0.8385,
      "step": 1640
    },
    {
      "epoch": 0.4579310344827586,
      "grad_norm": 0.5559120178222656,
      "learning_rate": 0.00018877695680334696,
      "loss": 0.8519,
      "step": 1660
    },
    {
      "epoch": 0.463448275862069,
      "grad_norm": 0.5618451237678528,
      "learning_rate": 0.0001885094148534957,
      "loss": 0.9113,
      "step": 1680
    },
    {
      "epoch": 0.4689655172413793,
      "grad_norm": 0.44233062863349915,
      "learning_rate": 0.0001882389156477309,
      "loss": 0.8604,
      "step": 1700
    },
    {
      "epoch": 0.47448275862068967,
      "grad_norm": 0.4861069619655609,
      "learning_rate": 0.00018796546822390887,
      "loss": 0.8838,
      "step": 1720
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.7269774079322815,
      "learning_rate": 0.00018768908171839114,
      "loss": 0.8382,
      "step": 1740
    },
    {
      "epoch": 0.48551724137931035,
      "grad_norm": 0.48284631967544556,
      "learning_rate": 0.00018740976536573916,
      "loss": 0.9697,
      "step": 1760
    },
    {
      "epoch": 0.4910344827586207,
      "grad_norm": 0.42540881037712097,
      "learning_rate": 0.00018712752849840572,
      "loss": 0.9579,
      "step": 1780
    },
    {
      "epoch": 0.496551724137931,
      "grad_norm": 0.3825797438621521,
      "learning_rate": 0.00018684238054642312,
      "loss": 0.7844,
      "step": 1800
    },
    {
      "epoch": 0.5020689655172413,
      "grad_norm": 0.39403441548347473,
      "learning_rate": 0.00018655433103708822,
      "loss": 0.8708,
      "step": 1820
    },
    {
      "epoch": 0.5075862068965518,
      "grad_norm": 0.7805087566375732,
      "learning_rate": 0.00018626338959464394,
      "loss": 0.9457,
      "step": 1840
    },
    {
      "epoch": 0.5131034482758621,
      "grad_norm": 0.5290830731391907,
      "learning_rate": 0.00018596956593995798,
      "loss": 0.9511,
      "step": 1860
    },
    {
      "epoch": 0.5186206896551724,
      "grad_norm": 0.5254833102226257,
      "learning_rate": 0.00018567286989019764,
      "loss": 0.8647,
      "step": 1880
    },
    {
      "epoch": 0.5241379310344828,
      "grad_norm": 0.5608901381492615,
      "learning_rate": 0.00018537331135850212,
      "loss": 0.9267,
      "step": 1900
    },
    {
      "epoch": 0.5296551724137931,
      "grad_norm": 0.5262838006019592,
      "learning_rate": 0.0001850709003536511,
      "loss": 0.8239,
      "step": 1920
    },
    {
      "epoch": 0.5351724137931034,
      "grad_norm": 0.48634666204452515,
      "learning_rate": 0.0001847656469797306,
      "loss": 0.8574,
      "step": 1940
    },
    {
      "epoch": 0.5406896551724137,
      "grad_norm": 0.5204187631607056,
      "learning_rate": 0.00018445756143579506,
      "loss": 0.8526,
      "step": 1960
    },
    {
      "epoch": 0.5462068965517242,
      "grad_norm": 0.4385882318019867,
      "learning_rate": 0.0001841466540155268,
      "loss": 0.9036,
      "step": 1980
    },
    {
      "epoch": 0.5517241379310345,
      "grad_norm": 0.5065300464630127,
      "learning_rate": 0.00018383293510689197,
      "loss": 0.8967,
      "step": 2000
    },
    {
      "epoch": 0.5517241379310345,
      "eval_loss": 0.8556280732154846,
      "eval_runtime": 55.7061,
      "eval_samples_per_second": 16.156,
      "eval_steps_per_second": 2.029,
      "step": 2000
    },
    {
      "epoch": 0.5572413793103448,
      "grad_norm": 0.5919210910797119,
      "learning_rate": 0.00018351641519179354,
      "loss": 0.8608,
      "step": 2020
    },
    {
      "epoch": 0.5627586206896552,
      "grad_norm": 0.4926242530345917,
      "learning_rate": 0.00018319710484572104,
      "loss": 0.8219,
      "step": 2040
    },
    {
      "epoch": 0.5682758620689655,
      "grad_norm": 0.5024396181106567,
      "learning_rate": 0.00018287501473739724,
      "loss": 0.8371,
      "step": 2060
    },
    {
      "epoch": 0.5737931034482758,
      "grad_norm": 0.5865111947059631,
      "learning_rate": 0.00018255015562842165,
      "loss": 0.8181,
      "step": 2080
    },
    {
      "epoch": 0.5793103448275863,
      "grad_norm": 0.5380303263664246,
      "learning_rate": 0.0001822225383729111,
      "loss": 0.8836,
      "step": 2100
    },
    {
      "epoch": 0.5848275862068966,
      "grad_norm": 0.37308064103126526,
      "learning_rate": 0.00018189217391713673,
      "loss": 0.9832,
      "step": 2120
    },
    {
      "epoch": 0.5903448275862069,
      "grad_norm": 0.47739988565444946,
      "learning_rate": 0.00018155907329915874,
      "loss": 0.8245,
      "step": 2140
    },
    {
      "epoch": 0.5958620689655172,
      "grad_norm": 0.44890642166137695,
      "learning_rate": 0.0001812232476484572,
      "loss": 0.7949,
      "step": 2160
    },
    {
      "epoch": 0.6013793103448276,
      "grad_norm": 0.5299778580665588,
      "learning_rate": 0.00018088470818556043,
      "loss": 0.9544,
      "step": 2180
    },
    {
      "epoch": 0.6068965517241379,
      "grad_norm": 0.44985854625701904,
      "learning_rate": 0.00018054346622166988,
      "loss": 0.7666,
      "step": 2200
    },
    {
      "epoch": 0.6124137931034482,
      "grad_norm": 0.5390083193778992,
      "learning_rate": 0.00018019953315828247,
      "loss": 0.9498,
      "step": 2220
    },
    {
      "epoch": 0.6179310344827587,
      "grad_norm": 0.5399731993675232,
      "learning_rate": 0.00017985292048680943,
      "loss": 0.879,
      "step": 2240
    },
    {
      "epoch": 0.623448275862069,
      "grad_norm": 0.6362599730491638,
      "learning_rate": 0.00017950363978819247,
      "loss": 1.0162,
      "step": 2260
    },
    {
      "epoch": 0.6289655172413793,
      "grad_norm": 0.4254704415798187,
      "learning_rate": 0.00017915170273251677,
      "loss": 0.8618,
      "step": 2280
    },
    {
      "epoch": 0.6344827586206897,
      "grad_norm": 0.4018785059452057,
      "learning_rate": 0.00017879712107862105,
      "loss": 0.9423,
      "step": 2300
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6306220889091492,
      "learning_rate": 0.00017843990667370488,
      "loss": 0.93,
      "step": 2320
    },
    {
      "epoch": 0.6455172413793103,
      "grad_norm": 0.5868403315544128,
      "learning_rate": 0.0001780800714529325,
      "loss": 0.8326,
      "step": 2340
    },
    {
      "epoch": 0.6510344827586206,
      "grad_norm": 0.7213391065597534,
      "learning_rate": 0.00017771762743903438,
      "loss": 0.8186,
      "step": 2360
    },
    {
      "epoch": 0.6565517241379311,
      "grad_norm": 0.5278604626655579,
      "learning_rate": 0.00017735258674190534,
      "loss": 0.8335,
      "step": 2380
    },
    {
      "epoch": 0.6620689655172414,
      "grad_norm": 0.35719946026802063,
      "learning_rate": 0.00017698496155819994,
      "loss": 0.8946,
      "step": 2400
    },
    {
      "epoch": 0.6675862068965517,
      "grad_norm": 0.45128849148750305,
      "learning_rate": 0.000176614764170925,
      "loss": 0.9902,
      "step": 2420
    },
    {
      "epoch": 0.6731034482758621,
      "grad_norm": 0.5744403004646301,
      "learning_rate": 0.00017624200694902928,
      "loss": 0.9321,
      "step": 2440
    },
    {
      "epoch": 0.6786206896551724,
      "grad_norm": 0.5050639510154724,
      "learning_rate": 0.00017586670234699008,
      "loss": 0.8513,
      "step": 2460
    },
    {
      "epoch": 0.6841379310344827,
      "grad_norm": 0.5211362838745117,
      "learning_rate": 0.00017548886290439714,
      "loss": 0.894,
      "step": 2480
    },
    {
      "epoch": 0.6896551724137931,
      "grad_norm": 0.3828640580177307,
      "learning_rate": 0.00017510850124553379,
      "loss": 0.8629,
      "step": 2500
    },
    {
      "epoch": 0.6896551724137931,
      "eval_loss": 0.8508306741714478,
      "eval_runtime": 55.5953,
      "eval_samples_per_second": 16.188,
      "eval_steps_per_second": 2.033,
      "step": 2500
    },
    {
      "epoch": 0.6951724137931035,
      "grad_norm": 0.6124042272567749,
      "learning_rate": 0.00017472563007895494,
      "loss": 0.8831,
      "step": 2520
    },
    {
      "epoch": 0.7006896551724138,
      "grad_norm": 0.5203622579574585,
      "learning_rate": 0.00017434026219706271,
      "loss": 0.9167,
      "step": 2540
    },
    {
      "epoch": 0.7062068965517241,
      "grad_norm": 0.5144317746162415,
      "learning_rate": 0.00017395241047567884,
      "loss": 0.9013,
      "step": 2560
    },
    {
      "epoch": 0.7117241379310345,
      "grad_norm": 0.8426430225372314,
      "learning_rate": 0.00017356208787361452,
      "loss": 0.8002,
      "step": 2580
    },
    {
      "epoch": 0.7172413793103448,
      "grad_norm": 0.4693167805671692,
      "learning_rate": 0.00017316930743223742,
      "loss": 0.8918,
      "step": 2600
    },
    {
      "epoch": 0.7227586206896551,
      "grad_norm": 0.5645201206207275,
      "learning_rate": 0.000172774082275036,
      "loss": 0.93,
      "step": 2620
    },
    {
      "epoch": 0.7282758620689656,
      "grad_norm": 0.40569135546684265,
      "learning_rate": 0.00017237642560718103,
      "loss": 0.8331,
      "step": 2640
    },
    {
      "epoch": 0.7337931034482759,
      "grad_norm": 0.5490443110466003,
      "learning_rate": 0.00017197635071508418,
      "loss": 0.8716,
      "step": 2660
    },
    {
      "epoch": 0.7393103448275862,
      "grad_norm": 0.3810267448425293,
      "learning_rate": 0.00017157387096595445,
      "loss": 0.7978,
      "step": 2680
    },
    {
      "epoch": 0.7448275862068966,
      "grad_norm": 0.49828749895095825,
      "learning_rate": 0.0001711689998073513,
      "loss": 0.8622,
      "step": 2700
    },
    {
      "epoch": 0.7503448275862069,
      "grad_norm": 0.3839932084083557,
      "learning_rate": 0.00017076175076673536,
      "loss": 0.9994,
      "step": 2720
    },
    {
      "epoch": 0.7558620689655172,
      "grad_norm": 0.6158874034881592,
      "learning_rate": 0.0001703521374510166,
      "loss": 0.908,
      "step": 2740
    },
    {
      "epoch": 0.7613793103448275,
      "grad_norm": 0.47662660479545593,
      "learning_rate": 0.00016994017354609944,
      "loss": 0.8307,
      "step": 2760
    },
    {
      "epoch": 0.766896551724138,
      "grad_norm": 0.6657444834709167,
      "learning_rate": 0.00016952587281642578,
      "loss": 0.9808,
      "step": 2780
    },
    {
      "epoch": 0.7724137931034483,
      "grad_norm": 0.6514860391616821,
      "learning_rate": 0.00016910924910451493,
      "loss": 0.9654,
      "step": 2800
    },
    {
      "epoch": 0.7779310344827586,
      "grad_norm": 0.6927882432937622,
      "learning_rate": 0.00016869031633050109,
      "loss": 0.889,
      "step": 2820
    },
    {
      "epoch": 0.783448275862069,
      "grad_norm": 0.5219056010246277,
      "learning_rate": 0.0001682690884916684,
      "loss": 0.8494,
      "step": 2840
    },
    {
      "epoch": 0.7889655172413793,
      "grad_norm": 0.49070897698402405,
      "learning_rate": 0.000167845579661983,
      "loss": 0.777,
      "step": 2860
    },
    {
      "epoch": 0.7944827586206896,
      "grad_norm": 0.7006303668022156,
      "learning_rate": 0.00016741980399162317,
      "loss": 0.9778,
      "step": 2880
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.4734947383403778,
      "learning_rate": 0.0001669917757065062,
      "loss": 0.8467,
      "step": 2900
    },
    {
      "epoch": 0.8055172413793104,
      "grad_norm": 0.39424753189086914,
      "learning_rate": 0.00016656150910781327,
      "loss": 0.9406,
      "step": 2920
    },
    {
      "epoch": 0.8110344827586207,
      "grad_norm": 0.4872346520423889,
      "learning_rate": 0.0001661290185715116,
      "loss": 0.8598,
      "step": 2940
    },
    {
      "epoch": 0.8165517241379311,
      "grad_norm": 0.5385696887969971,
      "learning_rate": 0.00016569431854787398,
      "loss": 0.8942,
      "step": 2960
    },
    {
      "epoch": 0.8220689655172414,
      "grad_norm": 0.5510944724082947,
      "learning_rate": 0.00016525742356099623,
      "loss": 0.854,
      "step": 2980
    },
    {
      "epoch": 0.8275862068965517,
      "grad_norm": 0.5193353295326233,
      "learning_rate": 0.00016481834820831164,
      "loss": 0.8754,
      "step": 3000
    },
    {
      "epoch": 0.8275862068965517,
      "eval_loss": 0.8463521599769592,
      "eval_runtime": 55.6109,
      "eval_samples_per_second": 16.184,
      "eval_steps_per_second": 2.032,
      "step": 3000
    },
    {
      "epoch": 0.833103448275862,
      "grad_norm": 0.39459729194641113,
      "learning_rate": 0.00016437710716010347,
      "loss": 0.8449,
      "step": 3020
    },
    {
      "epoch": 0.8386206896551724,
      "grad_norm": 0.514905571937561,
      "learning_rate": 0.00016393371515901459,
      "loss": 0.8505,
      "step": 3040
    },
    {
      "epoch": 0.8441379310344828,
      "grad_norm": 0.37595805525779724,
      "learning_rate": 0.00016348818701955513,
      "loss": 0.8069,
      "step": 3060
    },
    {
      "epoch": 0.8496551724137931,
      "grad_norm": 0.7102001905441284,
      "learning_rate": 0.00016304053762760727,
      "loss": 0.8813,
      "step": 3080
    },
    {
      "epoch": 0.8551724137931035,
      "grad_norm": 0.545295238494873,
      "learning_rate": 0.00016259078193992804,
      "loss": 0.9106,
      "step": 3100
    },
    {
      "epoch": 0.8606896551724138,
      "grad_norm": 0.6588478684425354,
      "learning_rate": 0.00016213893498364952,
      "loss": 0.8112,
      "step": 3120
    },
    {
      "epoch": 0.8662068965517241,
      "grad_norm": 0.4980018138885498,
      "learning_rate": 0.00016168501185577678,
      "loss": 0.8324,
      "step": 3140
    },
    {
      "epoch": 0.8717241379310345,
      "grad_norm": 0.8012005686759949,
      "learning_rate": 0.00016122902772268343,
      "loss": 0.859,
      "step": 3160
    },
    {
      "epoch": 0.8772413793103448,
      "grad_norm": 0.9590784907341003,
      "learning_rate": 0.00016077099781960485,
      "loss": 0.9421,
      "step": 3180
    },
    {
      "epoch": 0.8827586206896552,
      "grad_norm": 0.5733968019485474,
      "learning_rate": 0.00016031093745012934,
      "loss": 0.8854,
      "step": 3200
    },
    {
      "epoch": 0.8882758620689655,
      "grad_norm": 0.45234566926956177,
      "learning_rate": 0.00015984886198568658,
      "loss": 0.8224,
      "step": 3220
    },
    {
      "epoch": 0.8937931034482759,
      "grad_norm": 0.5545419454574585,
      "learning_rate": 0.00015938478686503417,
      "loss": 0.8467,
      "step": 3240
    },
    {
      "epoch": 0.8993103448275862,
      "grad_norm": 0.6817270517349243,
      "learning_rate": 0.00015891872759374168,
      "loss": 0.888,
      "step": 3260
    },
    {
      "epoch": 0.9048275862068965,
      "grad_norm": 0.5060339570045471,
      "learning_rate": 0.0001584506997436728,
      "loss": 0.8833,
      "step": 3280
    },
    {
      "epoch": 0.9103448275862069,
      "grad_norm": 0.7710272669792175,
      "learning_rate": 0.0001579807189524648,
      "loss": 0.887,
      "step": 3300
    },
    {
      "epoch": 0.9158620689655173,
      "grad_norm": 0.5263886451721191,
      "learning_rate": 0.00015750880092300616,
      "loss": 0.8721,
      "step": 3320
    },
    {
      "epoch": 0.9213793103448276,
      "grad_norm": 0.5077070593833923,
      "learning_rate": 0.00015703496142291197,
      "loss": 0.8848,
      "step": 3340
    },
    {
      "epoch": 0.926896551724138,
      "grad_norm": 0.3177604079246521,
      "learning_rate": 0.00015655921628399705,
      "loss": 0.8268,
      "step": 3360
    },
    {
      "epoch": 0.9324137931034483,
      "grad_norm": 0.6812832355499268,
      "learning_rate": 0.00015608158140174695,
      "loss": 0.8275,
      "step": 3380
    },
    {
      "epoch": 0.9379310344827586,
      "grad_norm": 0.5724748373031616,
      "learning_rate": 0.00015560207273478688,
      "loss": 0.775,
      "step": 3400
    },
    {
      "epoch": 0.9434482758620689,
      "grad_norm": 0.4905480444431305,
      "learning_rate": 0.0001551207063043485,
      "loss": 0.8301,
      "step": 3420
    },
    {
      "epoch": 0.9489655172413793,
      "grad_norm": 0.4541856646537781,
      "learning_rate": 0.00015463749819373464,
      "loss": 0.9442,
      "step": 3440
    },
    {
      "epoch": 0.9544827586206897,
      "grad_norm": 0.5960450768470764,
      "learning_rate": 0.00015415246454778198,
      "loss": 0.8899,
      "step": 3460
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.5158142447471619,
      "learning_rate": 0.00015366562157232146,
      "loss": 0.8226,
      "step": 3480
    },
    {
      "epoch": 0.9655172413793104,
      "grad_norm": 0.4934851825237274,
      "learning_rate": 0.000153176985533637,
      "loss": 0.8883,
      "step": 3500
    },
    {
      "epoch": 0.9655172413793104,
      "eval_loss": 0.8417446613311768,
      "eval_runtime": 55.6036,
      "eval_samples_per_second": 16.186,
      "eval_steps_per_second": 2.032,
      "step": 3500
    },
    {
      "epoch": 0.9710344827586207,
      "grad_norm": 0.6939823627471924,
      "learning_rate": 0.00015268657275792184,
      "loss": 0.7662,
      "step": 3520
    },
    {
      "epoch": 0.976551724137931,
      "grad_norm": 0.6584959030151367,
      "learning_rate": 0.0001521943996307332,
      "loss": 0.9486,
      "step": 3540
    },
    {
      "epoch": 0.9820689655172414,
      "grad_norm": 1.7111412286758423,
      "learning_rate": 0.0001517004825964448,
      "loss": 0.83,
      "step": 3560
    },
    {
      "epoch": 0.9875862068965517,
      "grad_norm": 0.42072734236717224,
      "learning_rate": 0.00015120483815769727,
      "loss": 0.7987,
      "step": 3580
    },
    {
      "epoch": 0.993103448275862,
      "grad_norm": 0.4380055069923401,
      "learning_rate": 0.00015070748287484697,
      "loss": 0.9073,
      "step": 3600
    },
    {
      "epoch": 0.9986206896551724,
      "grad_norm": 0.6571781635284424,
      "learning_rate": 0.00015020843336541252,
      "loss": 0.8075,
      "step": 3620
    },
    {
      "epoch": 1.0041379310344827,
      "grad_norm": 0.5878548622131348,
      "learning_rate": 0.00014970770630351964,
      "loss": 0.7639,
      "step": 3640
    },
    {
      "epoch": 1.0096551724137932,
      "grad_norm": 0.49535027146339417,
      "learning_rate": 0.0001492053184193441,
      "loss": 0.7895,
      "step": 3660
    },
    {
      "epoch": 1.0151724137931035,
      "grad_norm": 0.457662969827652,
      "learning_rate": 0.00014870128649855264,
      "loss": 0.8009,
      "step": 3680
    },
    {
      "epoch": 1.0206896551724138,
      "grad_norm": 0.40567436814308167,
      "learning_rate": 0.00014819562738174215,
      "loss": 0.8016,
      "step": 3700
    },
    {
      "epoch": 1.0262068965517241,
      "grad_norm": 0.4480375051498413,
      "learning_rate": 0.00014768835796387709,
      "loss": 0.8312,
      "step": 3720
    },
    {
      "epoch": 1.0317241379310345,
      "grad_norm": 0.5118411779403687,
      "learning_rate": 0.0001471794951937248,
      "loss": 0.6992,
      "step": 3740
    },
    {
      "epoch": 1.0372413793103448,
      "grad_norm": 0.7544519305229187,
      "learning_rate": 0.00014666905607328945,
      "loss": 0.7574,
      "step": 3760
    },
    {
      "epoch": 1.042758620689655,
      "grad_norm": 0.8044895529747009,
      "learning_rate": 0.00014615705765724376,
      "loss": 0.9354,
      "step": 3780
    },
    {
      "epoch": 1.0482758620689656,
      "grad_norm": 0.5251914858818054,
      "learning_rate": 0.00014564351705235936,
      "loss": 0.81,
      "step": 3800
    },
    {
      "epoch": 1.053793103448276,
      "grad_norm": 0.7373799681663513,
      "learning_rate": 0.0001451284514169351,
      "loss": 0.8102,
      "step": 3820
    },
    {
      "epoch": 1.0593103448275862,
      "grad_norm": 0.58539217710495,
      "learning_rate": 0.00014461187796022378,
      "loss": 0.8705,
      "step": 3840
    },
    {
      "epoch": 1.0648275862068965,
      "grad_norm": 0.714353621006012,
      "learning_rate": 0.00014409381394185717,
      "loss": 0.7122,
      "step": 3860
    },
    {
      "epoch": 1.0703448275862069,
      "grad_norm": 0.3922564685344696,
      "learning_rate": 0.00014357427667126935,
      "loss": 0.7569,
      "step": 3880
    },
    {
      "epoch": 1.0758620689655172,
      "grad_norm": 0.4664427936077118,
      "learning_rate": 0.00014305328350711836,
      "loss": 0.8314,
      "step": 3900
    },
    {
      "epoch": 1.0813793103448275,
      "grad_norm": 0.40945979952812195,
      "learning_rate": 0.00014253085185670627,
      "loss": 0.7738,
      "step": 3920
    },
    {
      "epoch": 1.086896551724138,
      "grad_norm": 0.5157955288887024,
      "learning_rate": 0.00014200699917539742,
      "loss": 0.771,
      "step": 3940
    },
    {
      "epoch": 1.0924137931034483,
      "grad_norm": 0.9496232867240906,
      "learning_rate": 0.00014148174296603532,
      "loss": 0.8458,
      "step": 3960
    },
    {
      "epoch": 1.0979310344827586,
      "grad_norm": 0.6163925528526306,
      "learning_rate": 0.00014095510077835786,
      "loss": 0.8306,
      "step": 3980
    },
    {
      "epoch": 1.103448275862069,
      "grad_norm": 0.7068076729774475,
      "learning_rate": 0.00014042709020841093,
      "loss": 0.888,
      "step": 4000
    },
    {
      "epoch": 1.103448275862069,
      "eval_loss": 0.8423939943313599,
      "eval_runtime": 55.6091,
      "eval_samples_per_second": 16.184,
      "eval_steps_per_second": 2.032,
      "step": 4000
    },
    {
      "epoch": 1.1089655172413793,
      "grad_norm": 0.7590630054473877,
      "learning_rate": 0.0001398977288979605,
      "loss": 0.7967,
      "step": 4020
    },
    {
      "epoch": 1.1144827586206896,
      "grad_norm": 0.4197620153427124,
      "learning_rate": 0.0001393670345339031,
      "loss": 0.7592,
      "step": 4040
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.32479429244995117,
      "learning_rate": 0.00013883502484767505,
      "loss": 0.7949,
      "step": 4060
    },
    {
      "epoch": 1.1255172413793104,
      "grad_norm": 0.5381736159324646,
      "learning_rate": 0.00013830171761465966,
      "loss": 0.7016,
      "step": 4080
    },
    {
      "epoch": 1.1310344827586207,
      "grad_norm": 0.5871397256851196,
      "learning_rate": 0.00013776713065359388,
      "loss": 0.7704,
      "step": 4100
    },
    {
      "epoch": 1.136551724137931,
      "grad_norm": 0.6489524841308594,
      "learning_rate": 0.00013723128182597247,
      "loss": 0.811,
      "step": 4120
    },
    {
      "epoch": 1.1420689655172414,
      "grad_norm": 0.41447004675865173,
      "learning_rate": 0.00013669418903545138,
      "loss": 0.7581,
      "step": 4140
    },
    {
      "epoch": 1.1475862068965517,
      "grad_norm": 0.661705732345581,
      "learning_rate": 0.00013615587022724966,
      "loss": 0.7761,
      "step": 4160
    },
    {
      "epoch": 1.153103448275862,
      "grad_norm": 0.505436897277832,
      "learning_rate": 0.0001356163433875496,
      "loss": 0.7707,
      "step": 4180
    },
    {
      "epoch": 1.1586206896551725,
      "grad_norm": 0.7252544164657593,
      "learning_rate": 0.00013507562654289611,
      "loss": 0.7353,
      "step": 4200
    },
    {
      "epoch": 1.1641379310344828,
      "grad_norm": 0.36569416522979736,
      "learning_rate": 0.0001345337377595942,
      "loss": 0.8164,
      "step": 4220
    },
    {
      "epoch": 1.1696551724137931,
      "grad_norm": 0.5055526494979858,
      "learning_rate": 0.00013399069514310544,
      "loss": 0.8173,
      "step": 4240
    },
    {
      "epoch": 1.1751724137931034,
      "grad_norm": 0.6307498812675476,
      "learning_rate": 0.00013344651683744302,
      "loss": 0.8478,
      "step": 4260
    },
    {
      "epoch": 1.1806896551724138,
      "grad_norm": 0.4714171290397644,
      "learning_rate": 0.00013290122102456553,
      "loss": 0.8723,
      "step": 4280
    },
    {
      "epoch": 1.186206896551724,
      "grad_norm": 0.6674216389656067,
      "learning_rate": 0.00013235482592376932,
      "loss": 0.7804,
      "step": 4300
    },
    {
      "epoch": 1.1917241379310344,
      "grad_norm": 0.6195053458213806,
      "learning_rate": 0.00013180734979107998,
      "loss": 0.7819,
      "step": 4320
    },
    {
      "epoch": 1.197241379310345,
      "grad_norm": 0.5631715655326843,
      "learning_rate": 0.00013125881091864238,
      "loss": 0.7775,
      "step": 4340
    },
    {
      "epoch": 1.2027586206896552,
      "grad_norm": 0.6251416206359863,
      "learning_rate": 0.00013070922763410927,
      "loss": 0.9571,
      "step": 4360
    },
    {
      "epoch": 1.2082758620689655,
      "grad_norm": 0.9550949931144714,
      "learning_rate": 0.0001301586183000291,
      "loss": 0.8221,
      "step": 4380
    },
    {
      "epoch": 1.2137931034482758,
      "grad_norm": 0.6303937435150146,
      "learning_rate": 0.00012960700131323246,
      "loss": 0.7327,
      "step": 4400
    },
    {
      "epoch": 1.2193103448275862,
      "grad_norm": 0.8196941018104553,
      "learning_rate": 0.00012905439510421733,
      "loss": 0.837,
      "step": 4420
    },
    {
      "epoch": 1.2248275862068965,
      "grad_norm": 0.6892649531364441,
      "learning_rate": 0.00012850081813653346,
      "loss": 0.7252,
      "step": 4440
    },
    {
      "epoch": 1.2303448275862068,
      "grad_norm": 0.9006329774856567,
      "learning_rate": 0.00012794628890616525,
      "loss": 0.8327,
      "step": 4460
    },
    {
      "epoch": 1.2358620689655173,
      "grad_norm": 0.8110414147377014,
      "learning_rate": 0.000127390825940914,
      "loss": 0.814,
      "step": 4480
    },
    {
      "epoch": 1.2413793103448276,
      "grad_norm": 0.5544276833534241,
      "learning_rate": 0.00012683444779977863,
      "loss": 0.7583,
      "step": 4500
    },
    {
      "epoch": 1.2413793103448276,
      "eval_loss": 0.8426775336265564,
      "eval_runtime": 55.6057,
      "eval_samples_per_second": 16.185,
      "eval_steps_per_second": 2.032,
      "step": 4500
    },
    {
      "epoch": 1.246896551724138,
      "grad_norm": 0.3830375671386719,
      "learning_rate": 0.00012627717307233576,
      "loss": 0.8501,
      "step": 4520
    },
    {
      "epoch": 1.2524137931034482,
      "grad_norm": 0.5051708221435547,
      "learning_rate": 0.0001257190203781185,
      "loss": 0.7441,
      "step": 4540
    },
    {
      "epoch": 1.2579310344827586,
      "grad_norm": 0.5764421224594116,
      "learning_rate": 0.00012516000836599448,
      "loss": 0.8128,
      "step": 4560
    },
    {
      "epoch": 1.263448275862069,
      "grad_norm": 0.7842892408370972,
      "learning_rate": 0.00012460015571354256,
      "loss": 0.7913,
      "step": 4580
    },
    {
      "epoch": 1.2689655172413792,
      "grad_norm": 0.6995367407798767,
      "learning_rate": 0.0001240394811264289,
      "loss": 0.8741,
      "step": 4600
    },
    {
      "epoch": 1.2744827586206897,
      "grad_norm": 0.4468839466571808,
      "learning_rate": 0.00012347800333778195,
      "loss": 0.8213,
      "step": 4620
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.633337140083313,
      "learning_rate": 0.0001229157411075666,
      "loss": 0.8459,
      "step": 4640
    },
    {
      "epoch": 1.2855172413793103,
      "grad_norm": 0.6400740742683411,
      "learning_rate": 0.00012235271322195718,
      "loss": 0.8141,
      "step": 4660
    },
    {
      "epoch": 1.2910344827586206,
      "grad_norm": 0.521125078201294,
      "learning_rate": 0.00012178893849271012,
      "loss": 0.7932,
      "step": 4680
    },
    {
      "epoch": 1.296551724137931,
      "grad_norm": 0.7813065648078918,
      "learning_rate": 0.00012122443575653501,
      "loss": 0.7705,
      "step": 4700
    },
    {
      "epoch": 1.3020689655172415,
      "grad_norm": 0.5191660523414612,
      "learning_rate": 0.00012065922387446562,
      "loss": 0.8048,
      "step": 4720
    },
    {
      "epoch": 1.3075862068965518,
      "grad_norm": 0.5767110586166382,
      "learning_rate": 0.00012009332173122936,
      "loss": 0.7655,
      "step": 4740
    },
    {
      "epoch": 1.3131034482758621,
      "grad_norm": 0.4305216670036316,
      "learning_rate": 0.00011952674823461665,
      "loss": 0.7363,
      "step": 4760
    },
    {
      "epoch": 1.3186206896551724,
      "grad_norm": 1.9242910146713257,
      "learning_rate": 0.00011895952231484888,
      "loss": 0.9074,
      "step": 4780
    },
    {
      "epoch": 1.3241379310344827,
      "grad_norm": 0.5297215580940247,
      "learning_rate": 0.00011839166292394615,
      "loss": 0.8167,
      "step": 4800
    },
    {
      "epoch": 1.329655172413793,
      "grad_norm": 0.6155877709388733,
      "learning_rate": 0.00011782318903509388,
      "loss": 0.8681,
      "step": 4820
    },
    {
      "epoch": 1.3351724137931034,
      "grad_norm": 0.6107254028320312,
      "learning_rate": 0.00011725411964200901,
      "loss": 0.7734,
      "step": 4840
    },
    {
      "epoch": 1.340689655172414,
      "grad_norm": 0.7931047081947327,
      "learning_rate": 0.00011668447375830525,
      "loss": 0.8098,
      "step": 4860
    },
    {
      "epoch": 1.3462068965517242,
      "grad_norm": 0.5527852773666382,
      "learning_rate": 0.00011611427041685797,
      "loss": 0.8698,
      "step": 4880
    },
    {
      "epoch": 1.3517241379310345,
      "grad_norm": 0.6756662726402283,
      "learning_rate": 0.00011554352866916811,
      "loss": 0.794,
      "step": 4900
    },
    {
      "epoch": 1.3572413793103448,
      "grad_norm": 0.43239110708236694,
      "learning_rate": 0.00011497226758472576,
      "loss": 0.7794,
      "step": 4920
    },
    {
      "epoch": 1.3627586206896551,
      "grad_norm": 0.5086984634399414,
      "learning_rate": 0.00011440050625037299,
      "loss": 0.8098,
      "step": 4940
    },
    {
      "epoch": 1.3682758620689655,
      "grad_norm": 0.6214100122451782,
      "learning_rate": 0.00011382826376966602,
      "loss": 0.8885,
      "step": 4960
    },
    {
      "epoch": 1.3737931034482758,
      "grad_norm": 0.5688912868499756,
      "learning_rate": 0.00011325555926223712,
      "loss": 0.7453,
      "step": 4980
    },
    {
      "epoch": 1.3793103448275863,
      "grad_norm": 0.4710949659347534,
      "learning_rate": 0.0001126824118631556,
      "loss": 0.8116,
      "step": 5000
    },
    {
      "epoch": 1.3793103448275863,
      "eval_loss": 0.8375769257545471,
      "eval_runtime": 55.598,
      "eval_samples_per_second": 16.188,
      "eval_steps_per_second": 2.032,
      "step": 5000
    },
    {
      "epoch": 1.3848275862068966,
      "grad_norm": 0.5094441175460815,
      "learning_rate": 0.00011210884072228863,
      "loss": 0.6959,
      "step": 5020
    },
    {
      "epoch": 1.390344827586207,
      "grad_norm": 0.48168379068374634,
      "learning_rate": 0.00011153486500366128,
      "loss": 0.8231,
      "step": 5040
    },
    {
      "epoch": 1.3958620689655172,
      "grad_norm": 0.7349138855934143,
      "learning_rate": 0.00011096050388481635,
      "loss": 0.7594,
      "step": 5060
    },
    {
      "epoch": 1.4013793103448275,
      "grad_norm": 0.6238212585449219,
      "learning_rate": 0.00011038577655617349,
      "loss": 0.8746,
      "step": 5080
    },
    {
      "epoch": 1.4068965517241379,
      "grad_norm": 0.5319984555244446,
      "learning_rate": 0.00010981070222038807,
      "loss": 0.8544,
      "step": 5100
    },
    {
      "epoch": 1.4124137931034482,
      "grad_norm": 0.5801003575325012,
      "learning_rate": 0.00010923530009170959,
      "loss": 0.7998,
      "step": 5120
    },
    {
      "epoch": 1.4179310344827587,
      "grad_norm": 0.8329951167106628,
      "learning_rate": 0.00010865958939533971,
      "loss": 0.8585,
      "step": 5140
    },
    {
      "epoch": 1.423448275862069,
      "grad_norm": 0.669818103313446,
      "learning_rate": 0.00010808358936678984,
      "loss": 0.7534,
      "step": 5160
    },
    {
      "epoch": 1.4289655172413793,
      "grad_norm": 0.42751550674438477,
      "learning_rate": 0.00010750731925123854,
      "loss": 0.8076,
      "step": 5180
    },
    {
      "epoch": 1.4344827586206896,
      "grad_norm": 0.6942312121391296,
      "learning_rate": 0.00010693079830288839,
      "loss": 0.7387,
      "step": 5200
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.5946295857429504,
      "learning_rate": 0.0001063540457843228,
      "loss": 0.7676,
      "step": 5220
    },
    {
      "epoch": 1.4455172413793105,
      "grad_norm": 0.6296123266220093,
      "learning_rate": 0.00010577708096586232,
      "loss": 0.8522,
      "step": 5240
    },
    {
      "epoch": 1.4510344827586206,
      "grad_norm": 0.7426137328147888,
      "learning_rate": 0.00010519992312492082,
      "loss": 0.8948,
      "step": 5260
    },
    {
      "epoch": 1.456551724137931,
      "grad_norm": 0.6149681210517883,
      "learning_rate": 0.00010462259154536136,
      "loss": 0.8527,
      "step": 5280
    },
    {
      "epoch": 1.4620689655172414,
      "grad_norm": 0.5838133692741394,
      "learning_rate": 0.00010404510551685198,
      "loss": 0.7237,
      "step": 5300
    },
    {
      "epoch": 1.4675862068965517,
      "grad_norm": 0.9499326944351196,
      "learning_rate": 0.00010346748433422109,
      "loss": 0.7462,
      "step": 5320
    },
    {
      "epoch": 1.473103448275862,
      "grad_norm": 0.6676777601242065,
      "learning_rate": 0.00010288974729681282,
      "loss": 0.8374,
      "step": 5340
    },
    {
      "epoch": 1.4786206896551723,
      "grad_norm": 0.4591485559940338,
      "learning_rate": 0.00010231191370784226,
      "loss": 0.7551,
      "step": 5360
    },
    {
      "epoch": 1.4841379310344829,
      "grad_norm": 0.49033841490745544,
      "learning_rate": 0.00010173400287375042,
      "loss": 0.7397,
      "step": 5380
    },
    {
      "epoch": 1.489655172413793,
      "grad_norm": 0.6688949465751648,
      "learning_rate": 0.00010115603410355923,
      "loss": 0.8222,
      "step": 5400
    },
    {
      "epoch": 1.4951724137931035,
      "grad_norm": 0.8695858716964722,
      "learning_rate": 0.00010057802670822635,
      "loss": 0.8465,
      "step": 5420
    },
    {
      "epoch": 1.5006896551724138,
      "grad_norm": 0.48671478033065796,
      "learning_rate": 0.0001,
      "loss": 0.8042,
      "step": 5440
    },
    {
      "epoch": 1.5062068965517241,
      "grad_norm": 0.6916370987892151,
      "learning_rate": 9.942197329177368e-05,
      "loss": 0.8589,
      "step": 5460
    },
    {
      "epoch": 1.5117241379310344,
      "grad_norm": 0.7524879574775696,
      "learning_rate": 9.88439658964408e-05,
      "loss": 0.7868,
      "step": 5480
    },
    {
      "epoch": 1.5172413793103448,
      "grad_norm": 0.5300508141517639,
      "learning_rate": 9.82659971262496e-05,
      "loss": 0.6963,
      "step": 5500
    },
    {
      "epoch": 1.5172413793103448,
      "eval_loss": 0.8358415961265564,
      "eval_runtime": 55.6043,
      "eval_samples_per_second": 16.186,
      "eval_steps_per_second": 2.032,
      "step": 5500
    },
    {
      "epoch": 1.5227586206896553,
      "grad_norm": 0.7176467180252075,
      "learning_rate": 9.768808629215775e-05,
      "loss": 0.8545,
      "step": 5520
    },
    {
      "epoch": 1.5282758620689654,
      "grad_norm": 0.5816313028335571,
      "learning_rate": 9.711025270318722e-05,
      "loss": 0.7133,
      "step": 5540
    },
    {
      "epoch": 1.533793103448276,
      "grad_norm": 0.45020875334739685,
      "learning_rate": 9.653251566577896e-05,
      "loss": 0.7987,
      "step": 5560
    },
    {
      "epoch": 1.5393103448275862,
      "grad_norm": 0.5233099460601807,
      "learning_rate": 9.595489448314804e-05,
      "loss": 0.8338,
      "step": 5580
    },
    {
      "epoch": 1.5448275862068965,
      "grad_norm": 0.5418205857276917,
      "learning_rate": 9.537740845463866e-05,
      "loss": 0.8155,
      "step": 5600
    },
    {
      "epoch": 1.5503448275862068,
      "grad_norm": 0.6758586168289185,
      "learning_rate": 9.480007687507919e-05,
      "loss": 0.8566,
      "step": 5620
    },
    {
      "epoch": 1.5558620689655172,
      "grad_norm": 0.43804627656936646,
      "learning_rate": 9.42229190341377e-05,
      "loss": 0.7817,
      "step": 5640
    },
    {
      "epoch": 1.5613793103448277,
      "grad_norm": 0.6314709782600403,
      "learning_rate": 9.364595421567719e-05,
      "loss": 0.7775,
      "step": 5660
    },
    {
      "epoch": 1.5668965517241378,
      "grad_norm": 0.5412606000900269,
      "learning_rate": 9.306920169711164e-05,
      "loss": 0.8158,
      "step": 5680
    },
    {
      "epoch": 1.5724137931034483,
      "grad_norm": 0.5412606596946716,
      "learning_rate": 9.249268074876149e-05,
      "loss": 0.8064,
      "step": 5700
    },
    {
      "epoch": 1.5779310344827586,
      "grad_norm": 0.703032910823822,
      "learning_rate": 9.191641063321018e-05,
      "loss": 0.9383,
      "step": 5720
    },
    {
      "epoch": 1.583448275862069,
      "grad_norm": 0.5685418844223022,
      "learning_rate": 9.134041060466032e-05,
      "loss": 0.7334,
      "step": 5740
    },
    {
      "epoch": 1.5889655172413795,
      "grad_norm": 0.5113705992698669,
      "learning_rate": 9.076469990829041e-05,
      "loss": 0.7144,
      "step": 5760
    },
    {
      "epoch": 1.5944827586206896,
      "grad_norm": 0.6219602823257446,
      "learning_rate": 9.018929777961196e-05,
      "loss": 0.7238,
      "step": 5780
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.760491132736206,
      "learning_rate": 8.961422344382652e-05,
      "loss": 0.7787,
      "step": 5800
    },
    {
      "epoch": 1.6055172413793104,
      "grad_norm": 0.5485342144966125,
      "learning_rate": 8.903949611518366e-05,
      "loss": 0.7078,
      "step": 5820
    },
    {
      "epoch": 1.6110344827586207,
      "grad_norm": 0.4384286403656006,
      "learning_rate": 8.846513499633873e-05,
      "loss": 0.83,
      "step": 5840
    },
    {
      "epoch": 1.616551724137931,
      "grad_norm": 0.3824947476387024,
      "learning_rate": 8.789115927771137e-05,
      "loss": 0.7485,
      "step": 5860
    },
    {
      "epoch": 1.6220689655172413,
      "grad_norm": 0.5580426454544067,
      "learning_rate": 8.731758813684442e-05,
      "loss": 0.8083,
      "step": 5880
    },
    {
      "epoch": 1.6275862068965519,
      "grad_norm": 0.7359814643859863,
      "learning_rate": 8.674444073776292e-05,
      "loss": 0.7101,
      "step": 5900
    },
    {
      "epoch": 1.633103448275862,
      "grad_norm": 0.5069840550422668,
      "learning_rate": 8.6171736230334e-05,
      "loss": 0.877,
      "step": 5920
    },
    {
      "epoch": 1.6386206896551725,
      "grad_norm": 0.6617475748062134,
      "learning_rate": 8.559949374962703e-05,
      "loss": 0.8082,
      "step": 5940
    },
    {
      "epoch": 1.6441379310344828,
      "grad_norm": 0.5166959166526794,
      "learning_rate": 8.502773241527423e-05,
      "loss": 0.6505,
      "step": 5960
    },
    {
      "epoch": 1.6496551724137931,
      "grad_norm": 0.49374744296073914,
      "learning_rate": 8.445647133083193e-05,
      "loss": 0.7292,
      "step": 5980
    },
    {
      "epoch": 1.6551724137931034,
      "grad_norm": 0.6295155882835388,
      "learning_rate": 8.38857295831421e-05,
      "loss": 0.8125,
      "step": 6000
    },
    {
      "epoch": 1.6551724137931034,
      "eval_loss": 0.8335646986961365,
      "eval_runtime": 55.5841,
      "eval_samples_per_second": 16.192,
      "eval_steps_per_second": 2.033,
      "step": 6000
    },
    {
      "epoch": 1.6606896551724137,
      "grad_norm": 0.6325940489768982,
      "learning_rate": 8.331552624169478e-05,
      "loss": 0.7315,
      "step": 6020
    },
    {
      "epoch": 1.6662068965517243,
      "grad_norm": 0.7344630360603333,
      "learning_rate": 8.274588035799102e-05,
      "loss": 0.8495,
      "step": 6040
    },
    {
      "epoch": 1.6717241379310344,
      "grad_norm": 0.6501750946044922,
      "learning_rate": 8.217681096490612e-05,
      "loss": 0.7096,
      "step": 6060
    },
    {
      "epoch": 1.677241379310345,
      "grad_norm": 0.620574414730072,
      "learning_rate": 8.160833707605386e-05,
      "loss": 0.7299,
      "step": 6080
    },
    {
      "epoch": 1.6827586206896552,
      "grad_norm": 0.5229501724243164,
      "learning_rate": 8.10404776851511e-05,
      "loss": 0.7555,
      "step": 6100
    },
    {
      "epoch": 1.6882758620689655,
      "grad_norm": 0.7608528137207031,
      "learning_rate": 8.047325176538338e-05,
      "loss": 0.82,
      "step": 6120
    },
    {
      "epoch": 1.6937931034482758,
      "grad_norm": 0.48304837942123413,
      "learning_rate": 7.990667826877065e-05,
      "loss": 0.8053,
      "step": 6140
    },
    {
      "epoch": 1.6993103448275861,
      "grad_norm": 0.6191536784172058,
      "learning_rate": 7.934077612553439e-05,
      "loss": 0.8266,
      "step": 6160
    },
    {
      "epoch": 1.7048275862068967,
      "grad_norm": 0.6255209445953369,
      "learning_rate": 7.8775564243465e-05,
      "loss": 0.7117,
      "step": 6180
    },
    {
      "epoch": 1.7103448275862068,
      "grad_norm": 0.6113137602806091,
      "learning_rate": 7.821106150728989e-05,
      "loss": 0.7641,
      "step": 6200
    },
    {
      "epoch": 1.7158620689655173,
      "grad_norm": 0.8561288118362427,
      "learning_rate": 7.764728677804282e-05,
      "loss": 0.8624,
      "step": 6220
    },
    {
      "epoch": 1.7213793103448276,
      "grad_norm": 0.6158691644668579,
      "learning_rate": 7.708425889243345e-05,
      "loss": 0.7606,
      "step": 6240
    },
    {
      "epoch": 1.726896551724138,
      "grad_norm": 0.5993173122406006,
      "learning_rate": 7.652199666221804e-05,
      "loss": 0.7146,
      "step": 6260
    },
    {
      "epoch": 1.7324137931034482,
      "grad_norm": 0.39117923378944397,
      "learning_rate": 7.596051887357113e-05,
      "loss": 0.7913,
      "step": 6280
    },
    {
      "epoch": 1.7379310344827585,
      "grad_norm": 0.5093742609024048,
      "learning_rate": 7.539984428645744e-05,
      "loss": 0.8887,
      "step": 6300
    },
    {
      "epoch": 1.743448275862069,
      "grad_norm": 0.33799198269844055,
      "learning_rate": 7.483999163400553e-05,
      "loss": 0.8442,
      "step": 6320
    },
    {
      "epoch": 1.7489655172413792,
      "grad_norm": 0.5425209403038025,
      "learning_rate": 7.42809796218815e-05,
      "loss": 0.7644,
      "step": 6340
    },
    {
      "epoch": 1.7544827586206897,
      "grad_norm": 0.4677186608314514,
      "learning_rate": 7.372282692766428e-05,
      "loss": 0.8063,
      "step": 6360
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.8055353760719299,
      "learning_rate": 7.31655522002214e-05,
      "loss": 0.7529,
      "step": 6380
    },
    {
      "epoch": 1.7655172413793103,
      "grad_norm": 0.5395655632019043,
      "learning_rate": 7.2609174059086e-05,
      "loss": 0.8977,
      "step": 6400
    },
    {
      "epoch": 1.7710344827586209,
      "grad_norm": 0.5474615693092346,
      "learning_rate": 7.205371109383476e-05,
      "loss": 0.7814,
      "step": 6420
    },
    {
      "epoch": 1.776551724137931,
      "grad_norm": 0.7383430004119873,
      "learning_rate": 7.149918186346656e-05,
      "loss": 0.7485,
      "step": 6440
    },
    {
      "epoch": 1.7820689655172415,
      "grad_norm": 0.678912341594696,
      "learning_rate": 7.09456048957827e-05,
      "loss": 0.8795,
      "step": 6460
    },
    {
      "epoch": 1.7875862068965516,
      "grad_norm": 0.46665677428245544,
      "learning_rate": 7.039299868676757e-05,
      "loss": 0.8079,
      "step": 6480
    },
    {
      "epoch": 1.793103448275862,
      "grad_norm": 0.6578496098518372,
      "learning_rate": 6.98413816999709e-05,
      "loss": 0.8356,
      "step": 6500
    },
    {
      "epoch": 1.793103448275862,
      "eval_loss": 0.830256998538971,
      "eval_runtime": 55.6099,
      "eval_samples_per_second": 16.184,
      "eval_steps_per_second": 2.032,
      "step": 6500
    },
    {
      "epoch": 1.7986206896551724,
      "grad_norm": 0.6432326436042786,
      "learning_rate": 6.929077236589075e-05,
      "loss": 0.9281,
      "step": 6520
    },
    {
      "epoch": 1.8041379310344827,
      "grad_norm": 0.39670249819755554,
      "learning_rate": 6.874118908135761e-05,
      "loss": 0.7628,
      "step": 6540
    },
    {
      "epoch": 1.8096551724137933,
      "grad_norm": 0.4189351201057434,
      "learning_rate": 6.819265020892004e-05,
      "loss": 0.8749,
      "step": 6560
    },
    {
      "epoch": 1.8151724137931033,
      "grad_norm": 0.6526283621788025,
      "learning_rate": 6.764517407623075e-05,
      "loss": 0.7212,
      "step": 6580
    },
    {
      "epoch": 1.8206896551724139,
      "grad_norm": 0.46309226751327515,
      "learning_rate": 6.70987789754345e-05,
      "loss": 0.74,
      "step": 6600
    },
    {
      "epoch": 1.8262068965517242,
      "grad_norm": 0.650040328502655,
      "learning_rate": 6.655348316255699e-05,
      "loss": 0.7195,
      "step": 6620
    },
    {
      "epoch": 1.8317241379310345,
      "grad_norm": 0.7896630167961121,
      "learning_rate": 6.600930485689454e-05,
      "loss": 0.8031,
      "step": 6640
    },
    {
      "epoch": 1.8372413793103448,
      "grad_norm": 0.8752404451370239,
      "learning_rate": 6.546626224040582e-05,
      "loss": 0.806,
      "step": 6660
    },
    {
      "epoch": 1.8427586206896551,
      "grad_norm": 0.6106979846954346,
      "learning_rate": 6.492437345710391e-05,
      "loss": 0.775,
      "step": 6680
    },
    {
      "epoch": 1.8482758620689657,
      "grad_norm": 0.7837079167366028,
      "learning_rate": 6.43836566124504e-05,
      "loss": 0.7719,
      "step": 6700
    },
    {
      "epoch": 1.8537931034482757,
      "grad_norm": 0.519496500492096,
      "learning_rate": 6.384412977275037e-05,
      "loss": 0.8208,
      "step": 6720
    },
    {
      "epoch": 1.8593103448275863,
      "grad_norm": 0.475234717130661,
      "learning_rate": 6.33058109645486e-05,
      "loss": 0.7602,
      "step": 6740
    },
    {
      "epoch": 1.8648275862068966,
      "grad_norm": 0.8941801190376282,
      "learning_rate": 6.276871817402754e-05,
      "loss": 0.8015,
      "step": 6760
    },
    {
      "epoch": 1.870344827586207,
      "grad_norm": 0.5479081273078918,
      "learning_rate": 6.223286934640612e-05,
      "loss": 0.7157,
      "step": 6780
    },
    {
      "epoch": 1.8758620689655172,
      "grad_norm": 0.659526526927948,
      "learning_rate": 6.169828238534035e-05,
      "loss": 0.7661,
      "step": 6800
    },
    {
      "epoch": 1.8813793103448275,
      "grad_norm": 0.5841846466064453,
      "learning_rate": 6.116497515232502e-05,
      "loss": 0.7852,
      "step": 6820
    },
    {
      "epoch": 1.886896551724138,
      "grad_norm": 0.5557541847229004,
      "learning_rate": 6.063296546609689e-05,
      "loss": 0.8961,
      "step": 6840
    },
    {
      "epoch": 1.8924137931034481,
      "grad_norm": 0.6068753004074097,
      "learning_rate": 6.010227110203952e-05,
      "loss": 0.851,
      "step": 6860
    },
    {
      "epoch": 1.8979310344827587,
      "grad_norm": 0.7632225751876831,
      "learning_rate": 5.957290979158907e-05,
      "loss": 0.7059,
      "step": 6880
    },
    {
      "epoch": 1.903448275862069,
      "grad_norm": 0.504246175289154,
      "learning_rate": 5.904489922164216e-05,
      "loss": 0.7777,
      "step": 6900
    },
    {
      "epoch": 1.9089655172413793,
      "grad_norm": 0.6755257248878479,
      "learning_rate": 5.851825703396474e-05,
      "loss": 0.7733,
      "step": 6920
    },
    {
      "epoch": 1.9144827586206896,
      "grad_norm": 0.6482420563697815,
      "learning_rate": 5.799300082460262e-05,
      "loss": 0.8653,
      "step": 6940
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.9089985489845276,
      "learning_rate": 5.746914814329376e-05,
      "loss": 0.8029,
      "step": 6960
    },
    {
      "epoch": 1.9255172413793105,
      "grad_norm": 0.6783102750778198,
      "learning_rate": 5.694671649288161e-05,
      "loss": 0.7464,
      "step": 6980
    },
    {
      "epoch": 1.9310344827586206,
      "grad_norm": 0.5452667474746704,
      "learning_rate": 5.6425723328730675e-05,
      "loss": 0.7462,
      "step": 7000
    },
    {
      "epoch": 1.9310344827586206,
      "eval_loss": 0.826606035232544,
      "eval_runtime": 55.606,
      "eval_samples_per_second": 16.185,
      "eval_steps_per_second": 2.032,
      "step": 7000
    },
    {
      "epoch": 1.936551724137931,
      "grad_norm": 0.7579900622367859,
      "learning_rate": 5.590618605814288e-05,
      "loss": 0.8447,
      "step": 7020
    },
    {
      "epoch": 1.9420689655172414,
      "grad_norm": 0.678571879863739,
      "learning_rate": 5.538812203977626e-05,
      "loss": 0.7875,
      "step": 7040
    },
    {
      "epoch": 1.9475862068965517,
      "grad_norm": 0.4245659112930298,
      "learning_rate": 5.487154858306491e-05,
      "loss": 0.7932,
      "step": 7060
    },
    {
      "epoch": 1.953103448275862,
      "grad_norm": 0.6837454438209534,
      "learning_rate": 5.435648294764062e-05,
      "loss": 0.8464,
      "step": 7080
    },
    {
      "epoch": 1.9586206896551723,
      "grad_norm": 0.7185384035110474,
      "learning_rate": 5.3842942342756253e-05,
      "loss": 0.7605,
      "step": 7100
    },
    {
      "epoch": 1.9641379310344829,
      "grad_norm": 0.5626212358474731,
      "learning_rate": 5.33309439267106e-05,
      "loss": 0.8403,
      "step": 7120
    },
    {
      "epoch": 1.969655172413793,
      "grad_norm": 0.5472968816757202,
      "learning_rate": 5.282050480627522e-05,
      "loss": 0.878,
      "step": 7140
    },
    {
      "epoch": 1.9751724137931035,
      "grad_norm": 0.5682467222213745,
      "learning_rate": 5.231164203612296e-05,
      "loss": 0.8052,
      "step": 7160
    },
    {
      "epoch": 1.9806896551724138,
      "grad_norm": 0.46798068284988403,
      "learning_rate": 5.1804372618257844e-05,
      "loss": 0.8361,
      "step": 7180
    },
    {
      "epoch": 1.986206896551724,
      "grad_norm": 0.5914784669876099,
      "learning_rate": 5.1298713501447394e-05,
      "loss": 0.768,
      "step": 7200
    },
    {
      "epoch": 1.9917241379310346,
      "grad_norm": 0.616749107837677,
      "learning_rate": 5.079468158065591e-05,
      "loss": 0.8549,
      "step": 7220
    },
    {
      "epoch": 1.9972413793103447,
      "grad_norm": 0.4230990409851074,
      "learning_rate": 5.029229369648038e-05,
      "loss": 0.7506,
      "step": 7240
    },
    {
      "epoch": 2.0027586206896553,
      "grad_norm": 0.6085913777351379,
      "learning_rate": 4.97915666345875e-05,
      "loss": 0.7131,
      "step": 7260
    },
    {
      "epoch": 2.0082758620689654,
      "grad_norm": 0.7460668683052063,
      "learning_rate": 4.929251712515306e-05,
      "loss": 0.734,
      "step": 7280
    },
    {
      "epoch": 2.013793103448276,
      "grad_norm": 0.5522270798683167,
      "learning_rate": 4.8795161842302726e-05,
      "loss": 0.8048,
      "step": 7300
    },
    {
      "epoch": 2.0193103448275864,
      "grad_norm": 0.6059530377388,
      "learning_rate": 4.829951740355518e-05,
      "loss": 0.7258,
      "step": 7320
    },
    {
      "epoch": 2.0248275862068965,
      "grad_norm": 0.5062352418899536,
      "learning_rate": 4.780560036926679e-05,
      "loss": 0.7024,
      "step": 7340
    },
    {
      "epoch": 2.030344827586207,
      "grad_norm": 0.7280174493789673,
      "learning_rate": 4.73134272420782e-05,
      "loss": 0.7473,
      "step": 7360
    },
    {
      "epoch": 2.035862068965517,
      "grad_norm": 0.8086897134780884,
      "learning_rate": 4.6823014466363026e-05,
      "loss": 0.7741,
      "step": 7380
    },
    {
      "epoch": 2.0413793103448277,
      "grad_norm": 0.5754838585853577,
      "learning_rate": 4.633437842767856e-05,
      "loss": 0.7521,
      "step": 7400
    },
    {
      "epoch": 2.0468965517241378,
      "grad_norm": 0.9841547012329102,
      "learning_rate": 4.584753545221803e-05,
      "loss": 0.7117,
      "step": 7420
    },
    {
      "epoch": 2.0524137931034483,
      "grad_norm": 0.5207954049110413,
      "learning_rate": 4.536250180626538e-05,
      "loss": 0.6883,
      "step": 7440
    },
    {
      "epoch": 2.057931034482759,
      "grad_norm": 0.6260561943054199,
      "learning_rate": 4.487929369565156e-05,
      "loss": 0.6986,
      "step": 7460
    },
    {
      "epoch": 2.063448275862069,
      "grad_norm": 0.5267530083656311,
      "learning_rate": 4.439792726521317e-05,
      "loss": 0.6126,
      "step": 7480
    },
    {
      "epoch": 2.0689655172413794,
      "grad_norm": 0.5415648221969604,
      "learning_rate": 4.391841859825306e-05,
      "loss": 0.689,
      "step": 7500
    },
    {
      "epoch": 2.0689655172413794,
      "eval_loss": 0.8417009711265564,
      "eval_runtime": 55.6113,
      "eval_samples_per_second": 16.184,
      "eval_steps_per_second": 2.032,
      "step": 7500
    },
    {
      "epoch": 2.0744827586206895,
      "grad_norm": 0.8993800282478333,
      "learning_rate": 4.344078371600293e-05,
      "loss": 0.8948,
      "step": 7520
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.5801590085029602,
      "learning_rate": 4.296503857708802e-05,
      "loss": 0.7906,
      "step": 7540
    },
    {
      "epoch": 2.08551724137931,
      "grad_norm": 0.8269116878509521,
      "learning_rate": 4.249119907699387e-05,
      "loss": 0.7663,
      "step": 7560
    },
    {
      "epoch": 2.0910344827586207,
      "grad_norm": 0.5642555356025696,
      "learning_rate": 4.201928104753522e-05,
      "loss": 0.6395,
      "step": 7580
    },
    {
      "epoch": 2.0965517241379312,
      "grad_norm": 0.6382835507392883,
      "learning_rate": 4.154930025632722e-05,
      "loss": 0.6081,
      "step": 7600
    },
    {
      "epoch": 2.1020689655172413,
      "grad_norm": 0.6216666102409363,
      "learning_rate": 4.108127240625831e-05,
      "loss": 0.6981,
      "step": 7620
    },
    {
      "epoch": 2.107586206896552,
      "grad_norm": 0.9045910835266113,
      "learning_rate": 4.061521313496587e-05,
      "loss": 0.6224,
      "step": 7640
    },
    {
      "epoch": 2.113103448275862,
      "grad_norm": 0.7293895483016968,
      "learning_rate": 4.015113801431343e-05,
      "loss": 0.6499,
      "step": 7660
    },
    {
      "epoch": 2.1186206896551725,
      "grad_norm": 0.6414892673492432,
      "learning_rate": 3.968906254987069e-05,
      "loss": 0.7703,
      "step": 7680
    },
    {
      "epoch": 2.1241379310344826,
      "grad_norm": 0.8853184580802917,
      "learning_rate": 3.922900218039516e-05,
      "loss": 0.7242,
      "step": 7700
    },
    {
      "epoch": 2.129655172413793,
      "grad_norm": 0.474843293428421,
      "learning_rate": 3.877097227731658e-05,
      "loss": 0.6717,
      "step": 7720
    },
    {
      "epoch": 2.1351724137931036,
      "grad_norm": 0.7369709014892578,
      "learning_rate": 3.831498814422323e-05,
      "loss": 0.74,
      "step": 7740
    },
    {
      "epoch": 2.1406896551724137,
      "grad_norm": 0.5732896327972412,
      "learning_rate": 3.786106501635046e-05,
      "loss": 0.6908,
      "step": 7760
    },
    {
      "epoch": 2.1462068965517243,
      "grad_norm": 0.8612032532691956,
      "learning_rate": 3.740921806007196e-05,
      "loss": 0.77,
      "step": 7780
    },
    {
      "epoch": 2.1517241379310343,
      "grad_norm": 0.6190850734710693,
      "learning_rate": 3.6959462372392763e-05,
      "loss": 0.7654,
      "step": 7800
    },
    {
      "epoch": 2.157241379310345,
      "grad_norm": 0.7477388381958008,
      "learning_rate": 3.651181298044489e-05,
      "loss": 0.6954,
      "step": 7820
    },
    {
      "epoch": 2.162758620689655,
      "grad_norm": 0.580047607421875,
      "learning_rate": 3.6066284840985444e-05,
      "loss": 0.706,
      "step": 7840
    },
    {
      "epoch": 2.1682758620689655,
      "grad_norm": 0.8266712427139282,
      "learning_rate": 3.562289283989656e-05,
      "loss": 0.6784,
      "step": 7860
    },
    {
      "epoch": 2.173793103448276,
      "grad_norm": 0.7575273513793945,
      "learning_rate": 3.51816517916884e-05,
      "loss": 0.7141,
      "step": 7880
    },
    {
      "epoch": 2.179310344827586,
      "grad_norm": 0.7334238886833191,
      "learning_rate": 3.4742576439003796e-05,
      "loss": 0.7117,
      "step": 7900
    },
    {
      "epoch": 2.1848275862068967,
      "grad_norm": 0.7478835582733154,
      "learning_rate": 3.430568145212605e-05,
      "loss": 0.693,
      "step": 7920
    },
    {
      "epoch": 2.1903448275862067,
      "grad_norm": 0.9178484678268433,
      "learning_rate": 3.3870981428488424e-05,
      "loss": 0.6838,
      "step": 7940
    },
    {
      "epoch": 2.1958620689655173,
      "grad_norm": 0.6263272166252136,
      "learning_rate": 3.3438490892186716e-05,
      "loss": 0.7549,
      "step": 7960
    },
    {
      "epoch": 2.2013793103448274,
      "grad_norm": 0.8946398496627808,
      "learning_rate": 3.3008224293493805e-05,
      "loss": 0.7204,
      "step": 7980
    },
    {
      "epoch": 2.206896551724138,
      "grad_norm": 0.6489587426185608,
      "learning_rate": 3.258019600837683e-05,
      "loss": 0.709,
      "step": 8000
    },
    {
      "epoch": 2.206896551724138,
      "eval_loss": 0.8456922769546509,
      "eval_runtime": 55.6104,
      "eval_samples_per_second": 16.184,
      "eval_steps_per_second": 2.032,
      "step": 8000
    },
    {
      "epoch": 2.2124137931034484,
      "grad_norm": 0.5527927875518799,
      "learning_rate": 3.215442033801701e-05,
      "loss": 0.6737,
      "step": 8020
    },
    {
      "epoch": 2.2179310344827585,
      "grad_norm": 0.7297716736793518,
      "learning_rate": 3.173091150833165e-05,
      "loss": 0.7722,
      "step": 8040
    },
    {
      "epoch": 2.223448275862069,
      "grad_norm": 0.6948462128639221,
      "learning_rate": 3.130968366949891e-05,
      "loss": 0.7899,
      "step": 8060
    },
    {
      "epoch": 2.228965517241379,
      "grad_norm": 0.48005443811416626,
      "learning_rate": 3.08907508954851e-05,
      "loss": 0.684,
      "step": 8080
    },
    {
      "epoch": 2.2344827586206897,
      "grad_norm": 0.754460334777832,
      "learning_rate": 3.047412718357423e-05,
      "loss": 0.7272,
      "step": 8100
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.725547194480896,
      "learning_rate": 3.0059826453900597e-05,
      "loss": 0.6985,
      "step": 8120
    },
    {
      "epoch": 2.2455172413793103,
      "grad_norm": 0.7900463938713074,
      "learning_rate": 2.964786254898343e-05,
      "loss": 0.7291,
      "step": 8140
    },
    {
      "epoch": 2.251034482758621,
      "grad_norm": 0.9314011335372925,
      "learning_rate": 2.9238249233264625e-05,
      "loss": 0.6932,
      "step": 8160
    },
    {
      "epoch": 2.256551724137931,
      "grad_norm": 0.5996291041374207,
      "learning_rate": 2.8831000192648715e-05,
      "loss": 0.7011,
      "step": 8180
    },
    {
      "epoch": 2.2620689655172415,
      "grad_norm": 0.6821136474609375,
      "learning_rate": 2.8426129034045546e-05,
      "loss": 0.7151,
      "step": 8200
    },
    {
      "epoch": 2.2675862068965515,
      "grad_norm": 0.6123153567314148,
      "learning_rate": 2.8023649284915854e-05,
      "loss": 0.6224,
      "step": 8220
    },
    {
      "epoch": 2.273103448275862,
      "grad_norm": 0.4090714752674103,
      "learning_rate": 2.762357439281903e-05,
      "loss": 0.6698,
      "step": 8240
    },
    {
      "epoch": 2.278620689655172,
      "grad_norm": 0.48206764459609985,
      "learning_rate": 2.7225917724964013e-05,
      "loss": 0.6376,
      "step": 8260
    },
    {
      "epoch": 2.2841379310344827,
      "grad_norm": 0.652693510055542,
      "learning_rate": 2.6830692567762605e-05,
      "loss": 0.6831,
      "step": 8280
    },
    {
      "epoch": 2.2896551724137932,
      "grad_norm": 0.8906734585762024,
      "learning_rate": 2.64379121263855e-05,
      "loss": 0.7738,
      "step": 8300
    },
    {
      "epoch": 2.2951724137931033,
      "grad_norm": 0.5183748006820679,
      "learning_rate": 2.604758952432119e-05,
      "loss": 0.7461,
      "step": 8320
    },
    {
      "epoch": 2.300689655172414,
      "grad_norm": 0.7771262526512146,
      "learning_rate": 2.5659737802937302e-05,
      "loss": 0.7065,
      "step": 8340
    },
    {
      "epoch": 2.306206896551724,
      "grad_norm": 0.8578557372093201,
      "learning_rate": 2.527436992104506e-05,
      "loss": 0.6525,
      "step": 8360
    },
    {
      "epoch": 2.3117241379310345,
      "grad_norm": 0.9154490232467651,
      "learning_rate": 2.4891498754466248e-05,
      "loss": 0.8471,
      "step": 8380
    },
    {
      "epoch": 2.317241379310345,
      "grad_norm": 0.862228274345398,
      "learning_rate": 2.4511137095602865e-05,
      "loss": 0.6766,
      "step": 8400
    },
    {
      "epoch": 2.322758620689655,
      "grad_norm": 0.6834472417831421,
      "learning_rate": 2.4133297653009934e-05,
      "loss": 0.6615,
      "step": 8420
    },
    {
      "epoch": 2.3282758620689656,
      "grad_norm": 0.5866715908050537,
      "learning_rate": 2.3757993050970705e-05,
      "loss": 0.7049,
      "step": 8440
    },
    {
      "epoch": 2.3337931034482757,
      "grad_norm": 0.6324809789657593,
      "learning_rate": 2.3385235829075002e-05,
      "loss": 0.7636,
      "step": 8460
    },
    {
      "epoch": 2.3393103448275863,
      "grad_norm": 0.9010282754898071,
      "learning_rate": 2.3015038441800096e-05,
      "loss": 0.7448,
      "step": 8480
    },
    {
      "epoch": 2.344827586206897,
      "grad_norm": 0.8956688046455383,
      "learning_rate": 2.2647413258094674e-05,
      "loss": 0.7085,
      "step": 8500
    },
    {
      "epoch": 2.344827586206897,
      "eval_loss": 0.8447980284690857,
      "eval_runtime": 55.6098,
      "eval_samples_per_second": 16.184,
      "eval_steps_per_second": 2.032,
      "step": 8500
    },
    {
      "epoch": 2.350344827586207,
      "grad_norm": 0.5108848214149475,
      "learning_rate": 2.2282372560965637e-05,
      "loss": 0.7639,
      "step": 8520
    },
    {
      "epoch": 2.3558620689655174,
      "grad_norm": 0.5671960115432739,
      "learning_rate": 2.1919928547067515e-05,
      "loss": 0.7107,
      "step": 8540
    },
    {
      "epoch": 2.3613793103448275,
      "grad_norm": 0.4953262507915497,
      "learning_rate": 2.156009332629516e-05,
      "loss": 0.6545,
      "step": 8560
    },
    {
      "epoch": 2.366896551724138,
      "grad_norm": 0.7718238234519958,
      "learning_rate": 2.1202878921378953e-05,
      "loss": 0.7033,
      "step": 8580
    },
    {
      "epoch": 2.372413793103448,
      "grad_norm": 0.46955227851867676,
      "learning_rate": 2.0848297267483254e-05,
      "loss": 0.7162,
      "step": 8600
    },
    {
      "epoch": 2.3779310344827587,
      "grad_norm": 0.7336955666542053,
      "learning_rate": 2.0496360211807554e-05,
      "loss": 0.6497,
      "step": 8620
    },
    {
      "epoch": 2.3834482758620688,
      "grad_norm": 0.962938129901886,
      "learning_rate": 2.014707951319057e-05,
      "loss": 0.6678,
      "step": 8640
    },
    {
      "epoch": 2.3889655172413793,
      "grad_norm": 0.8200909495353699,
      "learning_rate": 1.9800466841717546e-05,
      "loss": 0.7276,
      "step": 8660
    },
    {
      "epoch": 2.39448275862069,
      "grad_norm": 0.6408719420433044,
      "learning_rate": 1.9456533778330155e-05,
      "loss": 0.6857,
      "step": 8680
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.6872830986976624,
      "learning_rate": 1.9115291814439606e-05,
      "loss": 0.7645,
      "step": 8700
    },
    {
      "epoch": 2.4055172413793104,
      "grad_norm": 0.6757326722145081,
      "learning_rate": 1.8776752351542825e-05,
      "loss": 0.7391,
      "step": 8720
    },
    {
      "epoch": 2.4110344827586205,
      "grad_norm": 0.8451048731803894,
      "learning_rate": 1.8440926700841287e-05,
      "loss": 0.8036,
      "step": 8740
    },
    {
      "epoch": 2.416551724137931,
      "grad_norm": 0.7532112002372742,
      "learning_rate": 1.810782608286331e-05,
      "loss": 0.7341,
      "step": 8760
    },
    {
      "epoch": 2.4220689655172416,
      "grad_norm": 0.6511073112487793,
      "learning_rate": 1.7777461627088954e-05,
      "loss": 0.7155,
      "step": 8780
    },
    {
      "epoch": 2.4275862068965517,
      "grad_norm": 0.6623444557189941,
      "learning_rate": 1.744984437157834e-05,
      "loss": 0.6394,
      "step": 8800
    },
    {
      "epoch": 2.4331034482758622,
      "grad_norm": 0.9248653054237366,
      "learning_rate": 1.7124985262602787e-05,
      "loss": 0.6833,
      "step": 8820
    },
    {
      "epoch": 2.4386206896551723,
      "grad_norm": 0.6480008959770203,
      "learning_rate": 1.6802895154278975e-05,
      "loss": 0.6907,
      "step": 8840
    },
    {
      "epoch": 2.444137931034483,
      "grad_norm": 0.7186296582221985,
      "learning_rate": 1.6483584808206487e-05,
      "loss": 0.7238,
      "step": 8860
    },
    {
      "epoch": 2.449655172413793,
      "grad_norm": 0.530058741569519,
      "learning_rate": 1.616706489310804e-05,
      "loss": 0.8356,
      "step": 8880
    },
    {
      "epoch": 2.4551724137931035,
      "grad_norm": 0.6142144799232483,
      "learning_rate": 1.585334598447321e-05,
      "loss": 0.7065,
      "step": 8900
    },
    {
      "epoch": 2.4606896551724136,
      "grad_norm": 0.7753953337669373,
      "learning_rate": 1.5542438564204963e-05,
      "loss": 0.7651,
      "step": 8920
    },
    {
      "epoch": 2.466206896551724,
      "grad_norm": 0.44683247804641724,
      "learning_rate": 1.523435302026941e-05,
      "loss": 0.6631,
      "step": 8940
    },
    {
      "epoch": 2.4717241379310346,
      "grad_norm": 0.5416836738586426,
      "learning_rate": 1.492909964634892e-05,
      "loss": 0.6914,
      "step": 8960
    },
    {
      "epoch": 2.4772413793103447,
      "grad_norm": 0.7568871378898621,
      "learning_rate": 1.4626688641497921e-05,
      "loss": 0.7748,
      "step": 8980
    },
    {
      "epoch": 2.4827586206896552,
      "grad_norm": 0.5719817876815796,
      "learning_rate": 1.4327130109802367e-05,
      "loss": 0.6746,
      "step": 9000
    },
    {
      "epoch": 2.4827586206896552,
      "eval_loss": 0.8427196145057678,
      "eval_runtime": 55.6056,
      "eval_samples_per_second": 16.185,
      "eval_steps_per_second": 2.032,
      "step": 9000
    },
    {
      "epoch": 2.4882758620689653,
      "grad_norm": 1.074902892112732,
      "learning_rate": 1.403043406004203e-05,
      "loss": 0.6809,
      "step": 9020
    },
    {
      "epoch": 2.493793103448276,
      "grad_norm": 0.7553162574768066,
      "learning_rate": 1.3736610405356032e-05,
      "loss": 0.6897,
      "step": 9040
    },
    {
      "epoch": 2.4993103448275864,
      "grad_norm": 0.675365149974823,
      "learning_rate": 1.3445668962911816e-05,
      "loss": 0.7243,
      "step": 9060
    },
    {
      "epoch": 2.5048275862068965,
      "grad_norm": 0.6179068684577942,
      "learning_rate": 1.3157619453576897e-05,
      "loss": 0.6771,
      "step": 9080
    },
    {
      "epoch": 2.510344827586207,
      "grad_norm": 0.7524948120117188,
      "learning_rate": 1.2872471501594307e-05,
      "loss": 0.7166,
      "step": 9100
    },
    {
      "epoch": 2.515862068965517,
      "grad_norm": 0.7687254548072815,
      "learning_rate": 1.2590234634260856e-05,
      "loss": 0.7233,
      "step": 9120
    },
    {
      "epoch": 2.5213793103448277,
      "grad_norm": 0.7792304754257202,
      "learning_rate": 1.2310918281608873e-05,
      "loss": 0.7005,
      "step": 9140
    },
    {
      "epoch": 2.526896551724138,
      "grad_norm": 0.832353413105011,
      "learning_rate": 1.2034531776091173e-05,
      "loss": 0.711,
      "step": 9160
    },
    {
      "epoch": 2.5324137931034483,
      "grad_norm": 0.6167910099029541,
      "learning_rate": 1.1761084352269147e-05,
      "loss": 0.8114,
      "step": 9180
    },
    {
      "epoch": 2.5379310344827584,
      "grad_norm": 0.5578151345252991,
      "learning_rate": 1.1490585146504352e-05,
      "loss": 0.746,
      "step": 9200
    },
    {
      "epoch": 2.543448275862069,
      "grad_norm": 0.5495623350143433,
      "learning_rate": 1.1223043196653071e-05,
      "loss": 0.7203,
      "step": 9220
    },
    {
      "epoch": 2.5489655172413794,
      "grad_norm": 0.6924974322319031,
      "learning_rate": 1.095846744176452e-05,
      "loss": 0.7838,
      "step": 9240
    },
    {
      "epoch": 2.5544827586206895,
      "grad_norm": 0.7016906142234802,
      "learning_rate": 1.0696866721782095e-05,
      "loss": 0.706,
      "step": 9260
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.6215265393257141,
      "learning_rate": 1.0438249777247976e-05,
      "loss": 0.6684,
      "step": 9280
    },
    {
      "epoch": 2.56551724137931,
      "grad_norm": 0.7095919847488403,
      "learning_rate": 1.018262524901118e-05,
      "loss": 0.6843,
      "step": 9300
    },
    {
      "epoch": 2.5710344827586207,
      "grad_norm": 0.7822503447532654,
      "learning_rate": 9.930001677938772e-06,
      "loss": 0.7284,
      "step": 9320
    },
    {
      "epoch": 2.576551724137931,
      "grad_norm": 0.8128579258918762,
      "learning_rate": 9.680387504630562e-06,
      "loss": 0.7592,
      "step": 9340
    },
    {
      "epoch": 2.5820689655172413,
      "grad_norm": 1.0634409189224243,
      "learning_rate": 9.433791069137065e-06,
      "loss": 0.7179,
      "step": 9360
    },
    {
      "epoch": 2.587586206896552,
      "grad_norm": 0.6754664778709412,
      "learning_rate": 9.190220610680811e-06,
      "loss": 0.7189,
      "step": 9380
    },
    {
      "epoch": 2.593103448275862,
      "grad_norm": 0.8476975560188293,
      "learning_rate": 8.949684267381142e-06,
      "loss": 0.7322,
      "step": 9400
    },
    {
      "epoch": 2.5986206896551725,
      "grad_norm": 0.5451399683952332,
      "learning_rate": 8.712190075982185e-06,
      "loss": 0.6813,
      "step": 9420
    },
    {
      "epoch": 2.604137931034483,
      "grad_norm": 0.9847854375839233,
      "learning_rate": 8.477745971584483e-06,
      "loss": 0.7936,
      "step": 9440
    },
    {
      "epoch": 2.609655172413793,
      "grad_norm": 0.7820835113525391,
      "learning_rate": 8.246359787379731e-06,
      "loss": 0.7339,
      "step": 9460
    },
    {
      "epoch": 2.6151724137931036,
      "grad_norm": 0.5904259085655212,
      "learning_rate": 8.018039254389099e-06,
      "loss": 0.6066,
      "step": 9480
    },
    {
      "epoch": 2.6206896551724137,
      "grad_norm": 0.6685792803764343,
      "learning_rate": 7.792792001204975e-06,
      "loss": 0.6859,
      "step": 9500
    },
    {
      "epoch": 2.6206896551724137,
      "eval_loss": 0.8433082699775696,
      "eval_runtime": 55.6023,
      "eval_samples_per_second": 16.186,
      "eval_steps_per_second": 2.032,
      "step": 9500
    },
    {
      "epoch": 2.6262068965517242,
      "grad_norm": 0.7077465653419495,
      "learning_rate": 7.5706255537359884e-06,
      "loss": 0.6163,
      "step": 9520
    },
    {
      "epoch": 2.6317241379310343,
      "grad_norm": 0.6398816108703613,
      "learning_rate": 7.351547334955655e-06,
      "loss": 0.7451,
      "step": 9540
    },
    {
      "epoch": 2.637241379310345,
      "grad_norm": 0.7755081653594971,
      "learning_rate": 7.135564664654282e-06,
      "loss": 0.6035,
      "step": 9560
    },
    {
      "epoch": 2.642758620689655,
      "grad_norm": 0.519990086555481,
      "learning_rate": 6.9226847591944755e-06,
      "loss": 0.6592,
      "step": 9580
    },
    {
      "epoch": 2.6482758620689655,
      "grad_norm": 0.41656067967414856,
      "learning_rate": 6.7129147312699256e-06,
      "loss": 0.6343,
      "step": 9600
    },
    {
      "epoch": 2.653793103448276,
      "grad_norm": 0.8990775942802429,
      "learning_rate": 6.506261589667839e-06,
      "loss": 0.6314,
      "step": 9620
    },
    {
      "epoch": 2.659310344827586,
      "grad_norm": 0.6236045956611633,
      "learning_rate": 6.302732239034781e-06,
      "loss": 0.7488,
      "step": 9640
    },
    {
      "epoch": 2.6648275862068966,
      "grad_norm": 0.4193366765975952,
      "learning_rate": 6.102333479645916e-06,
      "loss": 0.6873,
      "step": 9660
    },
    {
      "epoch": 2.6703448275862067,
      "grad_norm": 0.5112384557723999,
      "learning_rate": 5.9050720071778365e-06,
      "loss": 0.7092,
      "step": 9680
    },
    {
      "epoch": 2.6758620689655173,
      "grad_norm": 0.9090181589126587,
      "learning_rate": 5.710954412484804e-06,
      "loss": 0.8307,
      "step": 9700
    },
    {
      "epoch": 2.681379310344828,
      "grad_norm": 0.7226502299308777,
      "learning_rate": 5.519987181378583e-06,
      "loss": 0.708,
      "step": 9720
    },
    {
      "epoch": 2.686896551724138,
      "grad_norm": 0.8778541088104248,
      "learning_rate": 5.332176694411761e-06,
      "loss": 0.6936,
      "step": 9740
    },
    {
      "epoch": 2.6924137931034484,
      "grad_norm": 0.9412556886672974,
      "learning_rate": 5.147529226664471e-06,
      "loss": 0.6739,
      "step": 9760
    },
    {
      "epoch": 2.6979310344827585,
      "grad_norm": 0.5868570804595947,
      "learning_rate": 4.96605094753485e-06,
      "loss": 0.6906,
      "step": 9780
    },
    {
      "epoch": 2.703448275862069,
      "grad_norm": 0.7611045241355896,
      "learning_rate": 4.787747920532781e-06,
      "loss": 0.7296,
      "step": 9800
    },
    {
      "epoch": 2.7089655172413796,
      "grad_norm": 0.749514639377594,
      "learning_rate": 4.612626103077377e-06,
      "loss": 0.7511,
      "step": 9820
    },
    {
      "epoch": 2.7144827586206897,
      "grad_norm": 0.5217835307121277,
      "learning_rate": 4.440691346297976e-06,
      "loss": 0.7117,
      "step": 9840
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.5418619513511658,
      "learning_rate": 4.271949394838515e-06,
      "loss": 0.6713,
      "step": 9860
    },
    {
      "epoch": 2.7255172413793103,
      "grad_norm": 0.535073459148407,
      "learning_rate": 4.106405886665698e-06,
      "loss": 0.7169,
      "step": 9880
    },
    {
      "epoch": 2.731034482758621,
      "grad_norm": 0.6729106307029724,
      "learning_rate": 3.944066352880615e-06,
      "loss": 0.6771,
      "step": 9900
    },
    {
      "epoch": 2.736551724137931,
      "grad_norm": 0.7984505295753479,
      "learning_rate": 3.784936217533852e-06,
      "loss": 0.6376,
      "step": 9920
    },
    {
      "epoch": 2.7420689655172414,
      "grad_norm": 0.6914479732513428,
      "learning_rate": 3.6290207974443826e-06,
      "loss": 0.7288,
      "step": 9940
    },
    {
      "epoch": 2.7475862068965515,
      "grad_norm": 0.6563369631767273,
      "learning_rate": 3.476325302021799e-06,
      "loss": 0.6858,
      "step": 9960
    },
    {
      "epoch": 2.753103448275862,
      "grad_norm": 0.7030794620513916,
      "learning_rate": 3.3268548330924077e-06,
      "loss": 0.7657,
      "step": 9980
    },
    {
      "epoch": 2.7586206896551726,
      "grad_norm": 0.7803323864936829,
      "learning_rate": 3.180614384728586e-06,
      "loss": 0.5742,
      "step": 10000
    },
    {
      "epoch": 2.7586206896551726,
      "eval_loss": 0.8439796566963196,
      "eval_runtime": 55.6126,
      "eval_samples_per_second": 16.183,
      "eval_steps_per_second": 2.032,
      "step": 10000
    }
  ],
  "logging_steps": 20,
  "max_steps": 10875,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.00420478976e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
