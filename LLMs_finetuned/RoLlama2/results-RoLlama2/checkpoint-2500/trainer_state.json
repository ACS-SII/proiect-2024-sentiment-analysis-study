{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.4705882352941178,
  "eval_steps": 500,
  "global_step": 2500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.011764705882352941,
      "grad_norm": 0.5370010137557983,
      "learning_rate": 9.999146252290264e-05,
      "loss": 1.1515,
      "step": 20
    },
    {
      "epoch": 0.023529411764705882,
      "grad_norm": 0.29683592915534973,
      "learning_rate": 9.996585300715116e-05,
      "loss": 0.7989,
      "step": 40
    },
    {
      "epoch": 0.03529411764705882,
      "grad_norm": 0.24912573397159576,
      "learning_rate": 9.99231801983717e-05,
      "loss": 0.7931,
      "step": 60
    },
    {
      "epoch": 0.047058823529411764,
      "grad_norm": 0.23487919569015503,
      "learning_rate": 9.986345866928941e-05,
      "loss": 0.6458,
      "step": 80
    },
    {
      "epoch": 0.058823529411764705,
      "grad_norm": 0.25113457441329956,
      "learning_rate": 9.978670881475172e-05,
      "loss": 0.805,
      "step": 100
    },
    {
      "epoch": 0.07058823529411765,
      "grad_norm": 0.23986975848674774,
      "learning_rate": 9.96929568447637e-05,
      "loss": 0.758,
      "step": 120
    },
    {
      "epoch": 0.08235294117647059,
      "grad_norm": 0.2023696005344391,
      "learning_rate": 9.958223477553714e-05,
      "loss": 0.7352,
      "step": 140
    },
    {
      "epoch": 0.09411764705882353,
      "grad_norm": 0.21185696125030518,
      "learning_rate": 9.94545804185573e-05,
      "loss": 0.7123,
      "step": 160
    },
    {
      "epoch": 0.10588235294117647,
      "grad_norm": 0.21200840175151825,
      "learning_rate": 9.931003736767013e-05,
      "loss": 0.739,
      "step": 180
    },
    {
      "epoch": 0.11764705882352941,
      "grad_norm": 0.20780259370803833,
      "learning_rate": 9.91486549841951e-05,
      "loss": 0.7419,
      "step": 200
    },
    {
      "epoch": 0.12941176470588237,
      "grad_norm": 0.22300252318382263,
      "learning_rate": 9.89704883800683e-05,
      "loss": 0.7243,
      "step": 220
    },
    {
      "epoch": 0.1411764705882353,
      "grad_norm": 0.260946661233902,
      "learning_rate": 9.877559839902184e-05,
      "loss": 0.7352,
      "step": 240
    },
    {
      "epoch": 0.15294117647058825,
      "grad_norm": 0.2119343876838684,
      "learning_rate": 9.85640515958057e-05,
      "loss": 0.734,
      "step": 260
    },
    {
      "epoch": 0.16470588235294117,
      "grad_norm": 0.27076613903045654,
      "learning_rate": 9.833592021345937e-05,
      "loss": 0.7706,
      "step": 280
    },
    {
      "epoch": 0.17647058823529413,
      "grad_norm": 0.21924835443496704,
      "learning_rate": 9.809128215864097e-05,
      "loss": 0.6611,
      "step": 300
    },
    {
      "epoch": 0.18823529411764706,
      "grad_norm": 0.23173177242279053,
      "learning_rate": 9.783022097502204e-05,
      "loss": 0.6937,
      "step": 320
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.2439296990633011,
      "learning_rate": 9.755282581475769e-05,
      "loss": 0.664,
      "step": 340
    },
    {
      "epoch": 0.21176470588235294,
      "grad_norm": 0.19825947284698486,
      "learning_rate": 9.725919140804099e-05,
      "loss": 0.6856,
      "step": 360
    },
    {
      "epoch": 0.2235294117647059,
      "grad_norm": 0.221049964427948,
      "learning_rate": 9.694941803075283e-05,
      "loss": 0.7039,
      "step": 380
    },
    {
      "epoch": 0.23529411764705882,
      "grad_norm": 0.18787933886051178,
      "learning_rate": 9.662361147021779e-05,
      "loss": 0.6786,
      "step": 400
    },
    {
      "epoch": 0.24705882352941178,
      "grad_norm": 0.23238053917884827,
      "learning_rate": 9.628188298907782e-05,
      "loss": 0.7177,
      "step": 420
    },
    {
      "epoch": 0.25882352941176473,
      "grad_norm": 0.2574536204338074,
      "learning_rate": 9.592434928729616e-05,
      "loss": 0.7215,
      "step": 440
    },
    {
      "epoch": 0.27058823529411763,
      "grad_norm": 0.20160441100597382,
      "learning_rate": 9.555113246230442e-05,
      "loss": 0.6447,
      "step": 460
    },
    {
      "epoch": 0.2823529411764706,
      "grad_norm": 0.268011212348938,
      "learning_rate": 9.516235996730645e-05,
      "loss": 0.6944,
      "step": 480
    },
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 0.19745750725269318,
      "learning_rate": 9.475816456775313e-05,
      "loss": 0.7045,
      "step": 500
    },
    {
      "epoch": 0.29411764705882354,
      "eval_loss": 0.6958617568016052,
      "eval_runtime": 70.9564,
      "eval_samples_per_second": 11.895,
      "eval_steps_per_second": 1.494,
      "step": 500
    },
    {
      "epoch": 0.3058823529411765,
      "grad_norm": 0.27618274092674255,
      "learning_rate": 9.43386842960031e-05,
      "loss": 0.7004,
      "step": 520
    },
    {
      "epoch": 0.3176470588235294,
      "grad_norm": 0.2182011753320694,
      "learning_rate": 9.39040624041849e-05,
      "loss": 0.6937,
      "step": 540
    },
    {
      "epoch": 0.32941176470588235,
      "grad_norm": 0.27151525020599365,
      "learning_rate": 9.345444731527642e-05,
      "loss": 0.6642,
      "step": 560
    },
    {
      "epoch": 0.3411764705882353,
      "grad_norm": 0.18490536510944366,
      "learning_rate": 9.298999257241863e-05,
      "loss": 0.6857,
      "step": 580
    },
    {
      "epoch": 0.35294117647058826,
      "grad_norm": 0.20919260382652283,
      "learning_rate": 9.251085678648072e-05,
      "loss": 0.7286,
      "step": 600
    },
    {
      "epoch": 0.36470588235294116,
      "grad_norm": 0.22539126873016357,
      "learning_rate": 9.201720358189464e-05,
      "loss": 0.7507,
      "step": 620
    },
    {
      "epoch": 0.3764705882352941,
      "grad_norm": 0.21214133501052856,
      "learning_rate": 9.150920154077754e-05,
      "loss": 0.6991,
      "step": 640
    },
    {
      "epoch": 0.38823529411764707,
      "grad_norm": 0.26539820432662964,
      "learning_rate": 9.098702414536107e-05,
      "loss": 0.7697,
      "step": 660
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.25048020482063293,
      "learning_rate": 9.045084971874738e-05,
      "loss": 0.7689,
      "step": 680
    },
    {
      "epoch": 0.4117647058823529,
      "grad_norm": 0.2035767287015915,
      "learning_rate": 8.9900861364012e-05,
      "loss": 0.7043,
      "step": 700
    },
    {
      "epoch": 0.4235294117647059,
      "grad_norm": 0.22206108272075653,
      "learning_rate": 8.933724690167417e-05,
      "loss": 0.6966,
      "step": 720
    },
    {
      "epoch": 0.43529411764705883,
      "grad_norm": 0.23212458193302155,
      "learning_rate": 8.876019880555649e-05,
      "loss": 0.7195,
      "step": 740
    },
    {
      "epoch": 0.4470588235294118,
      "grad_norm": 0.19034957885742188,
      "learning_rate": 8.816991413705516e-05,
      "loss": 0.7194,
      "step": 760
    },
    {
      "epoch": 0.4588235294117647,
      "grad_norm": 0.19605708122253418,
      "learning_rate": 8.756659447784368e-05,
      "loss": 0.7307,
      "step": 780
    },
    {
      "epoch": 0.47058823529411764,
      "grad_norm": 0.23491106927394867,
      "learning_rate": 8.695044586103296e-05,
      "loss": 0.7636,
      "step": 800
    },
    {
      "epoch": 0.4823529411764706,
      "grad_norm": 0.22242926061153412,
      "learning_rate": 8.632167870081121e-05,
      "loss": 0.7173,
      "step": 820
    },
    {
      "epoch": 0.49411764705882355,
      "grad_norm": 0.2823384702205658,
      "learning_rate": 8.568050772058762e-05,
      "loss": 0.7666,
      "step": 840
    },
    {
      "epoch": 0.5058823529411764,
      "grad_norm": 0.19607476890087128,
      "learning_rate": 8.502715187966455e-05,
      "loss": 0.7165,
      "step": 860
    },
    {
      "epoch": 0.5176470588235295,
      "grad_norm": 0.23043635487556458,
      "learning_rate": 8.436183429846313e-05,
      "loss": 0.6654,
      "step": 880
    },
    {
      "epoch": 0.5294117647058824,
      "grad_norm": 0.22698915004730225,
      "learning_rate": 8.368478218232787e-05,
      "loss": 0.7034,
      "step": 900
    },
    {
      "epoch": 0.5411764705882353,
      "grad_norm": 0.20793190598487854,
      "learning_rate": 8.299622674393614e-05,
      "loss": 0.6899,
      "step": 920
    },
    {
      "epoch": 0.5529411764705883,
      "grad_norm": 0.26890578866004944,
      "learning_rate": 8.229640312433937e-05,
      "loss": 0.7192,
      "step": 940
    },
    {
      "epoch": 0.5647058823529412,
      "grad_norm": 0.2485608607530594,
      "learning_rate": 8.158555031266254e-05,
      "loss": 0.764,
      "step": 960
    },
    {
      "epoch": 0.5764705882352941,
      "grad_norm": 0.2335241436958313,
      "learning_rate": 8.086391106448965e-05,
      "loss": 0.6686,
      "step": 980
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 0.2056477963924408,
      "learning_rate": 8.013173181896283e-05,
      "loss": 0.7209,
      "step": 1000
    },
    {
      "epoch": 0.5882352941176471,
      "eval_loss": 0.6851369738578796,
      "eval_runtime": 70.4917,
      "eval_samples_per_second": 11.973,
      "eval_steps_per_second": 1.504,
      "step": 1000
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.23608635365962982,
      "learning_rate": 7.938926261462366e-05,
      "loss": 0.7266,
      "step": 1020
    },
    {
      "epoch": 0.611764705882353,
      "grad_norm": 0.21749097108840942,
      "learning_rate": 7.863675700402526e-05,
      "loss": 0.6851,
      "step": 1040
    },
    {
      "epoch": 0.6235294117647059,
      "grad_norm": 0.2319597601890564,
      "learning_rate": 7.787447196714427e-05,
      "loss": 0.7048,
      "step": 1060
    },
    {
      "epoch": 0.6352941176470588,
      "grad_norm": 0.20108292996883392,
      "learning_rate": 7.710266782362247e-05,
      "loss": 0.6913,
      "step": 1080
    },
    {
      "epoch": 0.6470588235294118,
      "grad_norm": 0.2350572943687439,
      "learning_rate": 7.63216081438678e-05,
      "loss": 0.646,
      "step": 1100
    },
    {
      "epoch": 0.6588235294117647,
      "grad_norm": 0.23168829083442688,
      "learning_rate": 7.553155965904535e-05,
      "loss": 0.6881,
      "step": 1120
    },
    {
      "epoch": 0.6705882352941176,
      "grad_norm": 0.20318767428398132,
      "learning_rate": 7.473279216998895e-05,
      "loss": 0.6376,
      "step": 1140
    },
    {
      "epoch": 0.6823529411764706,
      "grad_norm": 0.2684336304664612,
      "learning_rate": 7.392557845506432e-05,
      "loss": 0.6641,
      "step": 1160
    },
    {
      "epoch": 0.6941176470588235,
      "grad_norm": 0.22263114154338837,
      "learning_rate": 7.311019417701566e-05,
      "loss": 0.6566,
      "step": 1180
    },
    {
      "epoch": 0.7058823529411765,
      "grad_norm": 0.27315235137939453,
      "learning_rate": 7.228691778882693e-05,
      "loss": 0.7698,
      "step": 1200
    },
    {
      "epoch": 0.7176470588235294,
      "grad_norm": 0.23413494229316711,
      "learning_rate": 7.145603043863045e-05,
      "loss": 0.7051,
      "step": 1220
    },
    {
      "epoch": 0.7294117647058823,
      "grad_norm": 0.23235797882080078,
      "learning_rate": 7.061781587369519e-05,
      "loss": 0.6739,
      "step": 1240
    },
    {
      "epoch": 0.7411764705882353,
      "grad_norm": 0.24858136475086212,
      "learning_rate": 6.977256034352712e-05,
      "loss": 0.7091,
      "step": 1260
    },
    {
      "epoch": 0.7529411764705882,
      "grad_norm": 0.24563747644424438,
      "learning_rate": 6.892055250211552e-05,
      "loss": 0.7657,
      "step": 1280
    },
    {
      "epoch": 0.7647058823529411,
      "grad_norm": 0.247879296541214,
      "learning_rate": 6.806208330935766e-05,
      "loss": 0.6452,
      "step": 1300
    },
    {
      "epoch": 0.7764705882352941,
      "grad_norm": 0.22676293551921844,
      "learning_rate": 6.719744593169641e-05,
      "loss": 0.6375,
      "step": 1320
    },
    {
      "epoch": 0.788235294117647,
      "grad_norm": 0.2757641673088074,
      "learning_rate": 6.632693564200416e-05,
      "loss": 0.6912,
      "step": 1340
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.22472380101680756,
      "learning_rate": 6.545084971874738e-05,
      "loss": 0.7396,
      "step": 1360
    },
    {
      "epoch": 0.8117647058823529,
      "grad_norm": 0.23957741260528564,
      "learning_rate": 6.456948734446624e-05,
      "loss": 0.6908,
      "step": 1380
    },
    {
      "epoch": 0.8235294117647058,
      "grad_norm": 0.2165699303150177,
      "learning_rate": 6.368314950360415e-05,
      "loss": 0.6916,
      "step": 1400
    },
    {
      "epoch": 0.8352941176470589,
      "grad_norm": 0.23698897659778595,
      "learning_rate": 6.279213887972179e-05,
      "loss": 0.7196,
      "step": 1420
    },
    {
      "epoch": 0.8470588235294118,
      "grad_norm": 0.2108544111251831,
      "learning_rate": 6.189675975213094e-05,
      "loss": 0.7231,
      "step": 1440
    },
    {
      "epoch": 0.8588235294117647,
      "grad_norm": 0.2166910618543625,
      "learning_rate": 6.099731789198344e-05,
      "loss": 0.7023,
      "step": 1460
    },
    {
      "epoch": 0.8705882352941177,
      "grad_norm": 0.2125781923532486,
      "learning_rate": 6.009412045785051e-05,
      "loss": 0.7049,
      "step": 1480
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 0.2465633749961853,
      "learning_rate": 5.918747589082853e-05,
      "loss": 0.7174,
      "step": 1500
    },
    {
      "epoch": 0.8823529411764706,
      "eval_loss": 0.6800586581230164,
      "eval_runtime": 70.2511,
      "eval_samples_per_second": 12.014,
      "eval_steps_per_second": 1.509,
      "step": 1500
    },
    {
      "epoch": 0.8941176470588236,
      "grad_norm": 0.22171317040920258,
      "learning_rate": 5.82776938092065e-05,
      "loss": 0.6829,
      "step": 1520
    },
    {
      "epoch": 0.9058823529411765,
      "grad_norm": 0.22229474782943726,
      "learning_rate": 5.736508490273188e-05,
      "loss": 0.684,
      "step": 1540
    },
    {
      "epoch": 0.9176470588235294,
      "grad_norm": 0.2142500877380371,
      "learning_rate": 5.644996082651017e-05,
      "loss": 0.6675,
      "step": 1560
    },
    {
      "epoch": 0.9294117647058824,
      "grad_norm": 0.19338445365428925,
      "learning_rate": 5.553263409457504e-05,
      "loss": 0.699,
      "step": 1580
    },
    {
      "epoch": 0.9411764705882353,
      "grad_norm": 0.22414444386959076,
      "learning_rate": 5.4613417973165106e-05,
      "loss": 0.6842,
      "step": 1600
    },
    {
      "epoch": 0.9529411764705882,
      "grad_norm": 0.23771537840366364,
      "learning_rate": 5.3692626373743706e-05,
      "loss": 0.7078,
      "step": 1620
    },
    {
      "epoch": 0.9647058823529412,
      "grad_norm": 0.23568812012672424,
      "learning_rate": 5.27705737457985e-05,
      "loss": 0.7002,
      "step": 1640
    },
    {
      "epoch": 0.9764705882352941,
      "grad_norm": 0.21443992853164673,
      "learning_rate": 5.184757496945726e-05,
      "loss": 0.6358,
      "step": 1660
    },
    {
      "epoch": 0.9882352941176471,
      "grad_norm": 0.250013530254364,
      "learning_rate": 5.092394524795649e-05,
      "loss": 0.6952,
      "step": 1680
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.2756432890892029,
      "learning_rate": 5e-05,
      "loss": 0.7239,
      "step": 1700
    },
    {
      "epoch": 1.011764705882353,
      "grad_norm": 0.2448132187128067,
      "learning_rate": 4.907605475204352e-05,
      "loss": 0.6924,
      "step": 1720
    },
    {
      "epoch": 1.0235294117647058,
      "grad_norm": 0.23330578207969666,
      "learning_rate": 4.8152425030542766e-05,
      "loss": 0.6395,
      "step": 1740
    },
    {
      "epoch": 1.035294117647059,
      "grad_norm": 0.23526020348072052,
      "learning_rate": 4.72294262542015e-05,
      "loss": 0.6743,
      "step": 1760
    },
    {
      "epoch": 1.0470588235294118,
      "grad_norm": 0.22453990578651428,
      "learning_rate": 4.6307373626256306e-05,
      "loss": 0.6191,
      "step": 1780
    },
    {
      "epoch": 1.0588235294117647,
      "grad_norm": 0.3087408244609833,
      "learning_rate": 4.5386582026834906e-05,
      "loss": 0.6429,
      "step": 1800
    },
    {
      "epoch": 1.0705882352941176,
      "grad_norm": 0.2683138847351074,
      "learning_rate": 4.446736590542497e-05,
      "loss": 0.7258,
      "step": 1820
    },
    {
      "epoch": 1.0823529411764705,
      "grad_norm": 0.24123112857341766,
      "learning_rate": 4.3550039173489845e-05,
      "loss": 0.719,
      "step": 1840
    },
    {
      "epoch": 1.0941176470588236,
      "grad_norm": 0.23589830100536346,
      "learning_rate": 4.2634915097268115e-05,
      "loss": 0.6544,
      "step": 1860
    },
    {
      "epoch": 1.1058823529411765,
      "grad_norm": 0.21290820837020874,
      "learning_rate": 4.1722306190793495e-05,
      "loss": 0.6583,
      "step": 1880
    },
    {
      "epoch": 1.1176470588235294,
      "grad_norm": 0.26142552495002747,
      "learning_rate": 4.0812524109171476e-05,
      "loss": 0.7206,
      "step": 1900
    },
    {
      "epoch": 1.1294117647058823,
      "grad_norm": 0.24479535222053528,
      "learning_rate": 3.99058795421495e-05,
      "loss": 0.6667,
      "step": 1920
    },
    {
      "epoch": 1.1411764705882352,
      "grad_norm": 0.31094565987586975,
      "learning_rate": 3.9002682108016585e-05,
      "loss": 0.6725,
      "step": 1940
    },
    {
      "epoch": 1.1529411764705881,
      "grad_norm": 0.28802043199539185,
      "learning_rate": 3.8103240247869075e-05,
      "loss": 0.7428,
      "step": 1960
    },
    {
      "epoch": 1.1647058823529413,
      "grad_norm": 0.3022250533103943,
      "learning_rate": 3.720786112027822e-05,
      "loss": 0.7143,
      "step": 1980
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 0.27279868721961975,
      "learning_rate": 3.631685049639586e-05,
      "loss": 0.7302,
      "step": 2000
    },
    {
      "epoch": 1.1764705882352942,
      "eval_loss": 0.6771367788314819,
      "eval_runtime": 71.6895,
      "eval_samples_per_second": 11.773,
      "eval_steps_per_second": 1.479,
      "step": 2000
    },
    {
      "epoch": 1.188235294117647,
      "grad_norm": 0.22959576547145844,
      "learning_rate": 3.543051265553377e-05,
      "loss": 0.6693,
      "step": 2020
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.2858272194862366,
      "learning_rate": 3.4549150281252636e-05,
      "loss": 0.755,
      "step": 2040
    },
    {
      "epoch": 1.2117647058823529,
      "grad_norm": 0.2892693281173706,
      "learning_rate": 3.367306435799584e-05,
      "loss": 0.7282,
      "step": 2060
    },
    {
      "epoch": 1.223529411764706,
      "grad_norm": 0.27151763439178467,
      "learning_rate": 3.2802554068303596e-05,
      "loss": 0.6053,
      "step": 2080
    },
    {
      "epoch": 1.2352941176470589,
      "grad_norm": 0.2579568326473236,
      "learning_rate": 3.1937916690642356e-05,
      "loss": 0.6309,
      "step": 2100
    },
    {
      "epoch": 1.2470588235294118,
      "grad_norm": 0.3010496497154236,
      "learning_rate": 3.107944749788449e-05,
      "loss": 0.6616,
      "step": 2120
    },
    {
      "epoch": 1.2588235294117647,
      "grad_norm": 0.270147442817688,
      "learning_rate": 3.0227439656472877e-05,
      "loss": 0.6779,
      "step": 2140
    },
    {
      "epoch": 1.2705882352941176,
      "grad_norm": 0.22154827415943146,
      "learning_rate": 2.9382184126304834e-05,
      "loss": 0.6496,
      "step": 2160
    },
    {
      "epoch": 1.2823529411764705,
      "grad_norm": 0.32540929317474365,
      "learning_rate": 2.8543969561369556e-05,
      "loss": 0.6693,
      "step": 2180
    },
    {
      "epoch": 1.2941176470588236,
      "grad_norm": 0.2816641926765442,
      "learning_rate": 2.771308221117309e-05,
      "loss": 0.714,
      "step": 2200
    },
    {
      "epoch": 1.3058823529411765,
      "grad_norm": 0.25483235716819763,
      "learning_rate": 2.688980582298435e-05,
      "loss": 0.6375,
      "step": 2220
    },
    {
      "epoch": 1.3176470588235294,
      "grad_norm": 0.28268834948539734,
      "learning_rate": 2.607442154493568e-05,
      "loss": 0.6852,
      "step": 2240
    },
    {
      "epoch": 1.3294117647058823,
      "grad_norm": 0.3052508533000946,
      "learning_rate": 2.5267207830011068e-05,
      "loss": 0.7015,
      "step": 2260
    },
    {
      "epoch": 1.3411764705882354,
      "grad_norm": 0.24105489253997803,
      "learning_rate": 2.446844034095466e-05,
      "loss": 0.665,
      "step": 2280
    },
    {
      "epoch": 1.3529411764705883,
      "grad_norm": 0.2670896053314209,
      "learning_rate": 2.3678391856132204e-05,
      "loss": 0.7078,
      "step": 2300
    },
    {
      "epoch": 1.3647058823529412,
      "grad_norm": 0.24449647963047028,
      "learning_rate": 2.2897332176377528e-05,
      "loss": 0.6259,
      "step": 2320
    },
    {
      "epoch": 1.3764705882352941,
      "grad_norm": 0.27838972210884094,
      "learning_rate": 2.2125528032855724e-05,
      "loss": 0.6675,
      "step": 2340
    },
    {
      "epoch": 1.388235294117647,
      "grad_norm": 0.308990478515625,
      "learning_rate": 2.136324299597474e-05,
      "loss": 0.7284,
      "step": 2360
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.32934466004371643,
      "learning_rate": 2.061073738537635e-05,
      "loss": 0.674,
      "step": 2380
    },
    {
      "epoch": 1.4117647058823528,
      "grad_norm": 0.25370994210243225,
      "learning_rate": 1.9868268181037185e-05,
      "loss": 0.7279,
      "step": 2400
    },
    {
      "epoch": 1.423529411764706,
      "grad_norm": 0.2574875056743622,
      "learning_rate": 1.9136088935510362e-05,
      "loss": 0.6274,
      "step": 2420
    },
    {
      "epoch": 1.4352941176470588,
      "grad_norm": 0.34218546748161316,
      "learning_rate": 1.8414449687337464e-05,
      "loss": 0.6893,
      "step": 2440
    },
    {
      "epoch": 1.4470588235294117,
      "grad_norm": 0.24450092017650604,
      "learning_rate": 1.7703596875660645e-05,
      "loss": 0.6117,
      "step": 2460
    },
    {
      "epoch": 1.4588235294117646,
      "grad_norm": 0.25094589591026306,
      "learning_rate": 1.700377325606388e-05,
      "loss": 0.6529,
      "step": 2480
    },
    {
      "epoch": 1.4705882352941178,
      "grad_norm": 0.2560117542743683,
      "learning_rate": 1.631521781767214e-05,
      "loss": 0.7205,
      "step": 2500
    },
    {
      "epoch": 1.4705882352941178,
      "eval_loss": 0.6748738288879395,
      "eval_runtime": 70.4142,
      "eval_samples_per_second": 11.986,
      "eval_steps_per_second": 1.505,
      "step": 2500
    }
  ],
  "logging_steps": 20,
  "max_steps": 3400,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.034726426598441e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
