{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.7761989342806395,
  "eval_steps": 500,
  "global_step": 3000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.011841326228537596,
      "grad_norm": 1.2260226011276245,
      "learning_rate": 9.999135095944002e-05,
      "loss": 1.2051,
      "step": 20
    },
    {
      "epoch": 0.023682652457075192,
      "grad_norm": 1.0885601043701172,
      "learning_rate": 9.996540682999613e-05,
      "loss": 0.9729,
      "step": 40
    },
    {
      "epoch": 0.035523978685612786,
      "grad_norm": 0.9789538383483887,
      "learning_rate": 9.99221765873415e-05,
      "loss": 0.936,
      "step": 60
    },
    {
      "epoch": 0.047365304914150384,
      "grad_norm": 1.3294116258621216,
      "learning_rate": 9.986167518748097e-05,
      "loss": 0.8889,
      "step": 80
    },
    {
      "epoch": 0.05920663114268798,
      "grad_norm": 0.811500608921051,
      "learning_rate": 9.9783923561577e-05,
      "loss": 0.8383,
      "step": 100
    },
    {
      "epoch": 0.07104795737122557,
      "grad_norm": 0.7640745043754578,
      "learning_rate": 9.968894860870827e-05,
      "loss": 0.8558,
      "step": 120
    },
    {
      "epoch": 0.08288928359976318,
      "grad_norm": 0.8340426087379456,
      "learning_rate": 9.957678318656352e-05,
      "loss": 0.7826,
      "step": 140
    },
    {
      "epoch": 0.09473060982830077,
      "grad_norm": 0.8135404586791992,
      "learning_rate": 9.944746610007418e-05,
      "loss": 0.9057,
      "step": 160
    },
    {
      "epoch": 0.10657193605683836,
      "grad_norm": 0.6961303353309631,
      "learning_rate": 9.930104208798932e-05,
      "loss": 0.7864,
      "step": 180
    },
    {
      "epoch": 0.11841326228537596,
      "grad_norm": 0.6270473003387451,
      "learning_rate": 9.913756180739768e-05,
      "loss": 0.8887,
      "step": 200
    },
    {
      "epoch": 0.13025458851391356,
      "grad_norm": 0.9126933217048645,
      "learning_rate": 9.895708181620241e-05,
      "loss": 0.8934,
      "step": 220
    },
    {
      "epoch": 0.14209591474245115,
      "grad_norm": 0.9390139579772949,
      "learning_rate": 9.875966455355403e-05,
      "loss": 0.8409,
      "step": 240
    },
    {
      "epoch": 0.15393724097098876,
      "grad_norm": 0.7951534390449524,
      "learning_rate": 9.854537831824906e-05,
      "loss": 0.8459,
      "step": 260
    },
    {
      "epoch": 0.16577856719952636,
      "grad_norm": 0.7630338072776794,
      "learning_rate": 9.831429724510107e-05,
      "loss": 0.8142,
      "step": 280
    },
    {
      "epoch": 0.17761989342806395,
      "grad_norm": 0.8459346294403076,
      "learning_rate": 9.806650127929308e-05,
      "loss": 0.8638,
      "step": 300
    },
    {
      "epoch": 0.18946121965660154,
      "grad_norm": 0.649561882019043,
      "learning_rate": 9.780207614871942e-05,
      "loss": 0.8829,
      "step": 320
    },
    {
      "epoch": 0.20130254588513913,
      "grad_norm": 0.7507839202880859,
      "learning_rate": 9.752111333432728e-05,
      "loss": 0.86,
      "step": 340
    },
    {
      "epoch": 0.21314387211367672,
      "grad_norm": 0.8841726779937744,
      "learning_rate": 9.722371003846775e-05,
      "loss": 0.8937,
      "step": 360
    },
    {
      "epoch": 0.22498519834221434,
      "grad_norm": 0.8299487829208374,
      "learning_rate": 9.690996915126758e-05,
      "loss": 0.8359,
      "step": 380
    },
    {
      "epoch": 0.23682652457075193,
      "grad_norm": 0.7412981986999512,
      "learning_rate": 9.657999921503311e-05,
      "loss": 0.9186,
      "step": 400
    },
    {
      "epoch": 0.24866785079928952,
      "grad_norm": 0.843569815158844,
      "learning_rate": 9.623391438669883e-05,
      "loss": 0.8561,
      "step": 420
    },
    {
      "epoch": 0.2605091770278271,
      "grad_norm": 0.596942663192749,
      "learning_rate": 9.587183439833344e-05,
      "loss": 0.7647,
      "step": 440
    },
    {
      "epoch": 0.27235050325636473,
      "grad_norm": 0.7489450573921204,
      "learning_rate": 9.549388451571714e-05,
      "loss": 0.7817,
      "step": 460
    },
    {
      "epoch": 0.2841918294849023,
      "grad_norm": 0.6711798310279846,
      "learning_rate": 9.510019549500454e-05,
      "loss": 0.834,
      "step": 480
    },
    {
      "epoch": 0.2960331557134399,
      "grad_norm": 0.7649656534194946,
      "learning_rate": 9.469090353748793e-05,
      "loss": 0.7627,
      "step": 500
    },
    {
      "epoch": 0.2960331557134399,
      "eval_loss": 0.8026648759841919,
      "eval_runtime": 74.4076,
      "eval_samples_per_second": 11.262,
      "eval_steps_per_second": 1.411,
      "step": 500
    },
    {
      "epoch": 0.30787448194197753,
      "grad_norm": 0.7399727702140808,
      "learning_rate": 9.426615024247698e-05,
      "loss": 0.7985,
      "step": 520
    },
    {
      "epoch": 0.3197158081705151,
      "grad_norm": 0.6621334552764893,
      "learning_rate": 9.382608255831075e-05,
      "loss": 0.8273,
      "step": 540
    },
    {
      "epoch": 0.3315571343990527,
      "grad_norm": 0.6280637383460999,
      "learning_rate": 9.337085273151924e-05,
      "loss": 0.8046,
      "step": 560
    },
    {
      "epoch": 0.3433984606275903,
      "grad_norm": 0.6207943558692932,
      "learning_rate": 9.290061825415185e-05,
      "loss": 0.8046,
      "step": 580
    },
    {
      "epoch": 0.3552397868561279,
      "grad_norm": 0.673464834690094,
      "learning_rate": 9.241554180929131e-05,
      "loss": 0.86,
      "step": 600
    },
    {
      "epoch": 0.36708111308466546,
      "grad_norm": 0.8091105222702026,
      "learning_rate": 9.191579121477148e-05,
      "loss": 0.8137,
      "step": 620
    },
    {
      "epoch": 0.3789224393132031,
      "grad_norm": 0.7477458119392395,
      "learning_rate": 9.14015393651188e-05,
      "loss": 0.858,
      "step": 640
    },
    {
      "epoch": 0.3907637655417407,
      "grad_norm": 0.6725465655326843,
      "learning_rate": 9.087296417173752e-05,
      "loss": 0.8251,
      "step": 660
    },
    {
      "epoch": 0.40260509177027826,
      "grad_norm": 0.9039843082427979,
      "learning_rate": 9.03302485013591e-05,
      "loss": 0.83,
      "step": 680
    },
    {
      "epoch": 0.4144464179988159,
      "grad_norm": 0.6853130459785461,
      "learning_rate": 8.977358011277736e-05,
      "loss": 0.8875,
      "step": 700
    },
    {
      "epoch": 0.42628774422735344,
      "grad_norm": 0.6997660398483276,
      "learning_rate": 8.920315159189116e-05,
      "loss": 0.7485,
      "step": 720
    },
    {
      "epoch": 0.43812907045589106,
      "grad_norm": 0.8099259734153748,
      "learning_rate": 8.861916028507707e-05,
      "loss": 0.8512,
      "step": 740
    },
    {
      "epoch": 0.4499703966844287,
      "grad_norm": 0.571018397808075,
      "learning_rate": 8.802180823091502e-05,
      "loss": 0.8534,
      "step": 760
    },
    {
      "epoch": 0.46181172291296624,
      "grad_norm": 0.5700215101242065,
      "learning_rate": 8.741130209029082e-05,
      "loss": 0.7812,
      "step": 780
    },
    {
      "epoch": 0.47365304914150386,
      "grad_norm": 0.6968947649002075,
      "learning_rate": 8.678785307489938e-05,
      "loss": 0.8329,
      "step": 800
    },
    {
      "epoch": 0.4854943753700414,
      "grad_norm": 0.7535921335220337,
      "learning_rate": 8.615167687417355e-05,
      "loss": 0.7875,
      "step": 820
    },
    {
      "epoch": 0.49733570159857904,
      "grad_norm": 0.6723275780677795,
      "learning_rate": 8.550299358066387e-05,
      "loss": 0.721,
      "step": 840
    },
    {
      "epoch": 0.5091770278271166,
      "grad_norm": 0.7006365060806274,
      "learning_rate": 8.484202761389497e-05,
      "loss": 0.8276,
      "step": 860
    },
    {
      "epoch": 0.5210183540556542,
      "grad_norm": 0.6230283379554749,
      "learning_rate": 8.416900764272509e-05,
      "loss": 0.8723,
      "step": 880
    },
    {
      "epoch": 0.5328596802841918,
      "grad_norm": 0.7828418612480164,
      "learning_rate": 8.34841665062353e-05,
      "loss": 0.8167,
      "step": 900
    },
    {
      "epoch": 0.5447010065127295,
      "grad_norm": 0.6770061254501343,
      "learning_rate": 8.278774113317633e-05,
      "loss": 0.7786,
      "step": 920
    },
    {
      "epoch": 0.5565423327412671,
      "grad_norm": 0.6579670906066895,
      "learning_rate": 8.207997246000012e-05,
      "loss": 0.734,
      "step": 940
    },
    {
      "epoch": 0.5683836589698046,
      "grad_norm": 0.5683915019035339,
      "learning_rate": 8.13611053475051e-05,
      "loss": 0.7919,
      "step": 960
    },
    {
      "epoch": 0.5802249851983422,
      "grad_norm": 0.8503963351249695,
      "learning_rate": 8.06313884961238e-05,
      "loss": 0.8016,
      "step": 980
    },
    {
      "epoch": 0.5920663114268798,
      "grad_norm": 0.6484171152114868,
      "learning_rate": 7.989107435988203e-05,
      "loss": 0.781,
      "step": 1000
    },
    {
      "epoch": 0.5920663114268798,
      "eval_loss": 0.7807708978652954,
      "eval_runtime": 73.5751,
      "eval_samples_per_second": 11.39,
      "eval_steps_per_second": 1.427,
      "step": 1000
    },
    {
      "epoch": 0.6039076376554174,
      "grad_norm": 0.7702401876449585,
      "learning_rate": 7.914041905905944e-05,
      "loss": 0.7706,
      "step": 1020
    },
    {
      "epoch": 0.6157489638839551,
      "grad_norm": 0.839359700679779,
      "learning_rate": 7.837968229158178e-05,
      "loss": 0.8132,
      "step": 1040
    },
    {
      "epoch": 0.6275902901124926,
      "grad_norm": 0.8079090714454651,
      "learning_rate": 7.760912724317533e-05,
      "loss": 0.8283,
      "step": 1060
    },
    {
      "epoch": 0.6394316163410302,
      "grad_norm": 0.6927472949028015,
      "learning_rate": 7.68290204963148e-05,
      "loss": 0.7069,
      "step": 1080
    },
    {
      "epoch": 0.6512729425695678,
      "grad_norm": 0.623825192451477,
      "learning_rate": 7.603963193799595e-05,
      "loss": 0.811,
      "step": 1100
    },
    {
      "epoch": 0.6631142687981054,
      "grad_norm": 0.6942513585090637,
      "learning_rate": 7.524123466636515e-05,
      "loss": 0.8163,
      "step": 1120
    },
    {
      "epoch": 0.6749555950266429,
      "grad_norm": 0.6125443577766418,
      "learning_rate": 7.44341048962378e-05,
      "loss": 0.7469,
      "step": 1140
    },
    {
      "epoch": 0.6867969212551805,
      "grad_norm": 0.8704622387886047,
      "learning_rate": 7.361852186353867e-05,
      "loss": 0.8164,
      "step": 1160
    },
    {
      "epoch": 0.6986382474837182,
      "grad_norm": 0.9000828266143799,
      "learning_rate": 7.279476772869693e-05,
      "loss": 0.7487,
      "step": 1180
    },
    {
      "epoch": 0.7104795737122558,
      "grad_norm": 0.7024686336517334,
      "learning_rate": 7.196312747902956e-05,
      "loss": 0.8019,
      "step": 1200
    },
    {
      "epoch": 0.7223208999407934,
      "grad_norm": 0.6864556074142456,
      "learning_rate": 7.112388883014656e-05,
      "loss": 0.8953,
      "step": 1220
    },
    {
      "epoch": 0.7341622261693309,
      "grad_norm": 0.5110988020896912,
      "learning_rate": 7.02773421264125e-05,
      "loss": 0.7655,
      "step": 1240
    },
    {
      "epoch": 0.7460035523978685,
      "grad_norm": 0.6635811924934387,
      "learning_rate": 6.942378024049843e-05,
      "loss": 0.7467,
      "step": 1260
    },
    {
      "epoch": 0.7578448786264061,
      "grad_norm": 0.7026558518409729,
      "learning_rate": 6.856349847205923e-05,
      "loss": 0.7766,
      "step": 1280
    },
    {
      "epoch": 0.7696862048549438,
      "grad_norm": 0.6738500595092773,
      "learning_rate": 6.76967944455712e-05,
      "loss": 0.8166,
      "step": 1300
    },
    {
      "epoch": 0.7815275310834814,
      "grad_norm": 0.6614165902137756,
      "learning_rate": 6.682396800736553e-05,
      "loss": 0.8308,
      "step": 1320
    },
    {
      "epoch": 0.7933688573120189,
      "grad_norm": 0.629245400428772,
      "learning_rate": 6.594532112189281e-05,
      "loss": 0.8069,
      "step": 1340
    },
    {
      "epoch": 0.8052101835405565,
      "grad_norm": 0.5795055031776428,
      "learning_rate": 6.506115776725509e-05,
      "loss": 0.8505,
      "step": 1360
    },
    {
      "epoch": 0.8170515097690941,
      "grad_norm": 0.6678797602653503,
      "learning_rate": 6.417178383004099e-05,
      "loss": 0.7433,
      "step": 1380
    },
    {
      "epoch": 0.8288928359976317,
      "grad_norm": 0.8002978563308716,
      "learning_rate": 6.327750699950073e-05,
      "loss": 0.8378,
      "step": 1400
    },
    {
      "epoch": 0.8407341622261694,
      "grad_norm": 0.7600347399711609,
      "learning_rate": 6.237863666109752e-05,
      "loss": 0.8125,
      "step": 1420
    },
    {
      "epoch": 0.8525754884547069,
      "grad_norm": 0.6524505615234375,
      "learning_rate": 6.147548378947195e-05,
      "loss": 0.8057,
      "step": 1440
    },
    {
      "epoch": 0.8644168146832445,
      "grad_norm": 0.6631894111633301,
      "learning_rate": 6.0568360840856734e-05,
      "loss": 0.7864,
      "step": 1460
    },
    {
      "epoch": 0.8762581409117821,
      "grad_norm": 0.6682089567184448,
      "learning_rate": 5.9657581644978914e-05,
      "loss": 0.755,
      "step": 1480
    },
    {
      "epoch": 0.8880994671403197,
      "grad_norm": 0.7190703749656677,
      "learning_rate": 5.874346129648674e-05,
      "loss": 0.7426,
      "step": 1500
    },
    {
      "epoch": 0.8880994671403197,
      "eval_loss": 0.7666730880737305,
      "eval_runtime": 62.2569,
      "eval_samples_per_second": 13.46,
      "eval_steps_per_second": 1.687,
      "step": 1500
    },
    {
      "epoch": 0.8999407933688574,
      "grad_norm": 0.5875744223594666,
      "learning_rate": 5.7826316045939045e-05,
      "loss": 0.797,
      "step": 1520
    },
    {
      "epoch": 0.9117821195973949,
      "grad_norm": 0.7713133692741394,
      "learning_rate": 5.690646319039468e-05,
      "loss": 0.7204,
      "step": 1540
    },
    {
      "epoch": 0.9236234458259325,
      "grad_norm": 0.6706702709197998,
      "learning_rate": 5.598422096363992e-05,
      "loss": 0.7819,
      "step": 1560
    },
    {
      "epoch": 0.9354647720544701,
      "grad_norm": 0.6326363682746887,
      "learning_rate": 5.505990842609178e-05,
      "loss": 0.8331,
      "step": 1580
    },
    {
      "epoch": 0.9473060982830077,
      "grad_norm": 0.5453073382377625,
      "learning_rate": 5.413384535441536e-05,
      "loss": 0.7085,
      "step": 1600
    },
    {
      "epoch": 0.9591474245115453,
      "grad_norm": 0.571882963180542,
      "learning_rate": 5.320635213089338e-05,
      "loss": 0.6994,
      "step": 1620
    },
    {
      "epoch": 0.9709887507400828,
      "grad_norm": 0.640470027923584,
      "learning_rate": 5.227774963258622e-05,
      "loss": 0.7688,
      "step": 1640
    },
    {
      "epoch": 0.9828300769686205,
      "grad_norm": 0.7164015173912048,
      "learning_rate": 5.134835912032073e-05,
      "loss": 0.7398,
      "step": 1660
    },
    {
      "epoch": 0.9946714031971581,
      "grad_norm": 0.5768494009971619,
      "learning_rate": 5.0418502127546395e-05,
      "loss": 0.7689,
      "step": 1680
    },
    {
      "epoch": 1.0065127294256957,
      "grad_norm": 0.623075008392334,
      "learning_rate": 4.948850034909705e-05,
      "loss": 0.74,
      "step": 1700
    },
    {
      "epoch": 1.0183540556542332,
      "grad_norm": 0.6545649170875549,
      "learning_rate": 4.855867552989678e-05,
      "loss": 0.6967,
      "step": 1720
    },
    {
      "epoch": 1.030195381882771,
      "grad_norm": 0.6872056722640991,
      "learning_rate": 4.76293493536486e-05,
      "loss": 0.7981,
      "step": 1740
    },
    {
      "epoch": 1.0420367081113084,
      "grad_norm": 0.8312661647796631,
      "learning_rate": 4.6700843331544175e-05,
      "loss": 0.7363,
      "step": 1760
    },
    {
      "epoch": 1.0538780343398462,
      "grad_norm": 0.7901685833930969,
      "learning_rate": 4.577347869103331e-05,
      "loss": 0.7757,
      "step": 1780
    },
    {
      "epoch": 1.0657193605683837,
      "grad_norm": 0.535915732383728,
      "learning_rate": 4.484757626469161e-05,
      "loss": 0.7228,
      "step": 1800
    },
    {
      "epoch": 1.0775606867969212,
      "grad_norm": 0.8115667700767517,
      "learning_rate": 4.392345637922467e-05,
      "loss": 0.7085,
      "step": 1820
    },
    {
      "epoch": 1.089402013025459,
      "grad_norm": 0.7989303469657898,
      "learning_rate": 4.300143874464734e-05,
      "loss": 0.8016,
      "step": 1840
    },
    {
      "epoch": 1.1012433392539964,
      "grad_norm": 0.6364026069641113,
      "learning_rate": 4.20818423436764e-05,
      "loss": 0.7026,
      "step": 1860
    },
    {
      "epoch": 1.1130846654825342,
      "grad_norm": 0.792894184589386,
      "learning_rate": 4.116498532137463e-05,
      "loss": 0.7142,
      "step": 1880
    },
    {
      "epoch": 1.1249259917110717,
      "grad_norm": 1.2248775959014893,
      "learning_rate": 4.0251184875085026e-05,
      "loss": 0.7657,
      "step": 1900
    },
    {
      "epoch": 1.1367673179396092,
      "grad_norm": 0.5478963851928711,
      "learning_rate": 3.934075714469251e-05,
      "loss": 0.7646,
      "step": 1920
    },
    {
      "epoch": 1.148608644168147,
      "grad_norm": 0.6860275864601135,
      "learning_rate": 3.843401710325175e-05,
      "loss": 0.7609,
      "step": 1940
    },
    {
      "epoch": 1.1604499703966844,
      "grad_norm": 0.6339688301086426,
      "learning_rate": 3.753127844801863e-05,
      "loss": 0.7674,
      "step": 1960
    },
    {
      "epoch": 1.1722912966252221,
      "grad_norm": 0.6766839623451233,
      "learning_rate": 3.663285349192284e-05,
      "loss": 0.6914,
      "step": 1980
    },
    {
      "epoch": 1.1841326228537596,
      "grad_norm": 0.7509782314300537,
      "learning_rate": 3.5739053055519875e-05,
      "loss": 0.79,
      "step": 2000
    },
    {
      "epoch": 1.1841326228537596,
      "eval_loss": 0.7603159546852112,
      "eval_runtime": 74.2058,
      "eval_samples_per_second": 11.293,
      "eval_steps_per_second": 1.415,
      "step": 2000
    },
    {
      "epoch": 1.1959739490822971,
      "grad_norm": 0.7277428507804871,
      "learning_rate": 3.4850186359458776e-05,
      "loss": 0.73,
      "step": 2020
    },
    {
      "epoch": 1.2078152753108349,
      "grad_norm": 0.698809027671814,
      "learning_rate": 3.3966560917503796e-05,
      "loss": 0.7145,
      "step": 2040
    },
    {
      "epoch": 1.2196566015393724,
      "grad_norm": 0.8228257298469543,
      "learning_rate": 3.308848243014646e-05,
      "loss": 0.7679,
      "step": 2060
    },
    {
      "epoch": 1.2314979277679101,
      "grad_norm": 0.6256019473075867,
      "learning_rate": 3.2216254678844804e-05,
      "loss": 0.732,
      "step": 2080
    },
    {
      "epoch": 1.2433392539964476,
      "grad_norm": 0.5735694169998169,
      "learning_rate": 3.1350179420926836e-05,
      "loss": 0.766,
      "step": 2100
    },
    {
      "epoch": 1.2551805802249851,
      "grad_norm": 0.6786401271820068,
      "learning_rate": 3.049055628519385e-05,
      "loss": 0.7105,
      "step": 2120
    },
    {
      "epoch": 1.2670219064535229,
      "grad_norm": 0.9537100791931152,
      "learning_rate": 2.963768266826055e-05,
      "loss": 0.8078,
      "step": 2140
    },
    {
      "epoch": 1.2788632326820604,
      "grad_norm": 0.6820197701454163,
      "learning_rate": 2.879185363166717e-05,
      "loss": 0.7654,
      "step": 2160
    },
    {
      "epoch": 1.290704558910598,
      "grad_norm": 0.822067379951477,
      "learning_rate": 2.7953361799799455e-05,
      "loss": 0.722,
      "step": 2180
    },
    {
      "epoch": 1.3025458851391356,
      "grad_norm": 0.673037588596344,
      "learning_rate": 2.7122497258651934e-05,
      "loss": 0.7292,
      "step": 2200
    },
    {
      "epoch": 1.3143872113676731,
      "grad_norm": 0.7479046583175659,
      "learning_rate": 2.6299547455469297e-05,
      "loss": 0.7095,
      "step": 2220
    },
    {
      "epoch": 1.3262285375962108,
      "grad_norm": 0.6903689503669739,
      "learning_rate": 2.5484797099300544e-05,
      "loss": 0.6821,
      "step": 2240
    },
    {
      "epoch": 1.3380698638247484,
      "grad_norm": 0.7338905334472656,
      "learning_rate": 2.46785280625008e-05,
      "loss": 0.737,
      "step": 2260
    },
    {
      "epoch": 1.349911190053286,
      "grad_norm": 0.7630199790000916,
      "learning_rate": 2.3881019283214078e-05,
      "loss": 0.7861,
      "step": 2280
    },
    {
      "epoch": 1.3617525162818236,
      "grad_norm": 0.8679471611976624,
      "learning_rate": 2.3092546668871566e-05,
      "loss": 0.7634,
      "step": 2300
    },
    {
      "epoch": 1.373593842510361,
      "grad_norm": 0.8391910791397095,
      "learning_rate": 2.2313383000738154e-05,
      "loss": 0.7475,
      "step": 2320
    },
    {
      "epoch": 1.3854351687388988,
      "grad_norm": 0.9662140011787415,
      "learning_rate": 2.1543797839540548e-05,
      "loss": 0.7506,
      "step": 2340
    },
    {
      "epoch": 1.3972764949674363,
      "grad_norm": 0.7400391697883606,
      "learning_rate": 2.078405743220973e-05,
      "loss": 0.7235,
      "step": 2360
    },
    {
      "epoch": 1.409117821195974,
      "grad_norm": 0.7381325364112854,
      "learning_rate": 2.003442461976958e-05,
      "loss": 0.7571,
      "step": 2380
    },
    {
      "epoch": 1.4209591474245116,
      "grad_norm": 0.6830160021781921,
      "learning_rate": 1.9295158746404118e-05,
      "loss": 0.767,
      "step": 2400
    },
    {
      "epoch": 1.432800473653049,
      "grad_norm": 0.7558512687683105,
      "learning_rate": 1.8566515569734293e-05,
      "loss": 0.7163,
      "step": 2420
    },
    {
      "epoch": 1.4446417998815868,
      "grad_norm": 0.8232250809669495,
      "learning_rate": 1.7848747172335622e-05,
      "loss": 0.6975,
      "step": 2440
    },
    {
      "epoch": 1.4564831261101243,
      "grad_norm": 0.6487805843353271,
      "learning_rate": 1.7142101874527416e-05,
      "loss": 0.7582,
      "step": 2460
    },
    {
      "epoch": 1.468324452338662,
      "grad_norm": 0.8679563403129578,
      "learning_rate": 1.644682414846332e-05,
      "loss": 0.7995,
      "step": 2480
    },
    {
      "epoch": 1.4801657785671996,
      "grad_norm": 0.9339338541030884,
      "learning_rate": 1.5763154533553486e-05,
      "loss": 0.7539,
      "step": 2500
    },
    {
      "epoch": 1.4801657785671996,
      "eval_loss": 0.7559289336204529,
      "eval_runtime": 73.7933,
      "eval_samples_per_second": 11.356,
      "eval_steps_per_second": 1.423,
      "step": 2500
    },
    {
      "epoch": 1.492007104795737,
      "grad_norm": 0.977693498134613,
      "learning_rate": 1.5091329553247096e-05,
      "loss": 0.7774,
      "step": 2520
    },
    {
      "epoch": 1.5038484310242746,
      "grad_norm": 0.7609195709228516,
      "learning_rate": 1.4431581633204261e-05,
      "loss": 0.8107,
      "step": 2540
    },
    {
      "epoch": 1.5156897572528123,
      "grad_norm": 0.7321317791938782,
      "learning_rate": 1.378413902088581e-05,
      "loss": 0.7282,
      "step": 2560
    },
    {
      "epoch": 1.52753108348135,
      "grad_norm": 0.9417128562927246,
      "learning_rate": 1.314922570658828e-05,
      "loss": 0.7033,
      "step": 2580
    },
    {
      "epoch": 1.5393724097098875,
      "grad_norm": 0.7929114103317261,
      "learning_rate": 1.252706134595199e-05,
      "loss": 0.7022,
      "step": 2600
    },
    {
      "epoch": 1.551213735938425,
      "grad_norm": 0.6509993076324463,
      "learning_rate": 1.1917861183968548e-05,
      "loss": 0.7401,
      "step": 2620
    },
    {
      "epoch": 1.5630550621669625,
      "grad_norm": 0.843619167804718,
      "learning_rate": 1.1321835980514345e-05,
      "loss": 0.7805,
      "step": 2640
    },
    {
      "epoch": 1.5748963883955003,
      "grad_norm": 0.7480360269546509,
      "learning_rate": 1.0739191937435777e-05,
      "loss": 0.7174,
      "step": 2660
    },
    {
      "epoch": 1.586737714624038,
      "grad_norm": 0.8848508596420288,
      "learning_rate": 1.0170130627211245e-05,
      "loss": 0.7529,
      "step": 2680
    },
    {
      "epoch": 1.5985790408525755,
      "grad_norm": 0.7513667941093445,
      "learning_rate": 9.614848923214887e-06,
      "loss": 0.7586,
      "step": 2700
    },
    {
      "epoch": 1.610420367081113,
      "grad_norm": 0.6454994678497314,
      "learning_rate": 9.073538931605929e-06,
      "loss": 0.7798,
      "step": 2720
    },
    {
      "epoch": 1.6222616933096505,
      "grad_norm": 0.6595513224601746,
      "learning_rate": 8.54638792486726e-06,
      "loss": 0.7456,
      "step": 2740
    },
    {
      "epoch": 1.6341030195381883,
      "grad_norm": 0.9391868710517883,
      "learning_rate": 8.033578277016445e-06,
      "loss": 0.7955,
      "step": 2760
    },
    {
      "epoch": 1.645944345766726,
      "grad_norm": 0.6458109617233276,
      "learning_rate": 7.535287400511215e-06,
      "loss": 0.7679,
      "step": 2780
    },
    {
      "epoch": 1.6577856719952635,
      "grad_norm": 0.8119723796844482,
      "learning_rate": 7.051687684871644e-06,
      "loss": 0.741,
      "step": 2800
    },
    {
      "epoch": 1.669626998223801,
      "grad_norm": 0.920330822467804,
      "learning_rate": 6.582946437039949e-06,
      "loss": 0.7478,
      "step": 2820
    },
    {
      "epoch": 1.6814683244523385,
      "grad_norm": 0.6895248889923096,
      "learning_rate": 6.1292258234987075e-06,
      "loss": 0.7204,
      "step": 2840
    },
    {
      "epoch": 1.6933096506808762,
      "grad_norm": 0.7547255754470825,
      "learning_rate": 5.6906828141675085e-06,
      "loss": 0.7086,
      "step": 2860
    },
    {
      "epoch": 1.705150976909414,
      "grad_norm": 0.9273020625114441,
      "learning_rate": 5.267469128097336e-06,
      "loss": 0.7062,
      "step": 2880
    },
    {
      "epoch": 1.7169923031379515,
      "grad_norm": 0.6265207529067993,
      "learning_rate": 4.859731180981647e-06,
      "loss": 0.7555,
      "step": 2900
    },
    {
      "epoch": 1.728833629366489,
      "grad_norm": 0.7460136413574219,
      "learning_rate": 4.467610034502162e-06,
      "loss": 0.7492,
      "step": 2920
    },
    {
      "epoch": 1.7406749555950265,
      "grad_norm": 0.7962234616279602,
      "learning_rate": 4.091241347526864e-06,
      "loss": 0.7656,
      "step": 2940
    },
    {
      "epoch": 1.7525162818235642,
      "grad_norm": 0.6602392196655273,
      "learning_rate": 3.7307553291773378e-06,
      "loss": 0.7554,
      "step": 2960
    },
    {
      "epoch": 1.764357608052102,
      "grad_norm": 0.8732659220695496,
      "learning_rate": 3.3862766937813427e-06,
      "loss": 0.7467,
      "step": 2980
    },
    {
      "epoch": 1.7761989342806395,
      "grad_norm": 0.5581203699111938,
      "learning_rate": 3.0579246177264597e-06,
      "loss": 0.6883,
      "step": 3000
    },
    {
      "epoch": 1.7761989342806395,
      "eval_loss": 0.7539908289909363,
      "eval_runtime": 73.3036,
      "eval_samples_per_second": 11.432,
      "eval_steps_per_second": 1.432,
      "step": 3000
    }
  ],
  "logging_steps": 20,
  "max_steps": 3378,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.625861133050839e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
